{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGRHpUtCrk8eq0PHyzUnSX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nullvoid-ky/introduction-to-machine-learning-and-deep-learning/blob/main/Lightgbm%26Xgboost_find_best_threshold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Setup & Installs (Kaggle usually has most of these; safe to re-run) =====\n",
        "!pip -q install kagglehub shap lightgbm xgboost\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "n9HvOO_ERM4E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ihjiHgHZQKDI"
      },
      "outputs": [],
      "source": [
        "# ถ้าในสภาพแวดล้อมคุณยังไม่มี ให้รันก่อน (Kaggle มักมีอยู่แล้ว)\n",
        "!pip install lightgbm xgboost -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"utkarshx27/american-companies-bankruptcy-prediction-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fACN98iiQOwY",
        "outputId": "8145a005-b004-4f7d-9ade-84da0408f355"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'american-companies-bankruptcy-prediction-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/american-companies-bankruptcy-prediction-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kagglehub import KaggleDatasetAdapter, load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "# Set the CSV file path **inside** the dataset (adjust if needed)\n",
        "# Explore the dataset directory printed below to confirm the file name.\n",
        "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "file_path = \"/kaggle/input/american-companies-bankruptcy-prediction-dataset/american_bankruptcy.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Loaded shape:\", df.shape)\n",
        "print(\"Columns:\\n\", list(df.columns))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "b3wF26zwQQKm",
        "outputId": "a1f5d632-41ce-4eaf-b429-a2dcc0cab282"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded shape: (78682, 21)\n",
            "Columns:\n",
            " ['company_name', 'status_label', 'year', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  company_name status_label  year       X1       X2      X3      X4       X5  \\\n",
              "0          C_1        alive  1999  511.267  833.107  18.373  89.031  336.018   \n",
              "1          C_1        alive  2000  485.856  713.811  18.577  64.367  320.590   \n",
              "2          C_1        alive  2001  436.656  526.477  22.496  27.207  286.588   \n",
              "3          C_1        alive  2002  396.412  496.747  27.172  30.745  259.954   \n",
              "4          C_1        alive  2003  432.204  523.302  26.680  47.491  247.245   \n",
              "\n",
              "       X6       X7  ...        X9      X10      X11     X12      X13      X14  \\\n",
              "0  35.163  128.348  ...  1024.333  740.998  180.447  70.658  191.226  163.816   \n",
              "1  18.531  115.187  ...   874.255  701.854  179.987  45.790  160.444  125.392   \n",
              "2 -58.939   77.528  ...   638.721  710.199  217.699   4.711  112.244  150.464   \n",
              "3 -12.410   66.322  ...   606.337  686.621  164.658   3.573  109.590  203.575   \n",
              "4   3.504  104.661  ...   651.958  709.292  248.666  20.811  128.656  131.261   \n",
              "\n",
              "       X15       X16      X17      X18  \n",
              "0  201.026  1024.333  401.483  935.302  \n",
              "1  204.065   874.255  361.642  809.888  \n",
              "2  139.603   638.721  399.964  611.514  \n",
              "3  124.106   606.337  391.633  575.592  \n",
              "4  131.884   651.958  407.608  604.467  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70568f17-f3ff-482a-8f72-30dbbc89774c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>company_name</th>\n",
              "      <th>status_label</th>\n",
              "      <th>year</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>...</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "      <th>X12</th>\n",
              "      <th>X13</th>\n",
              "      <th>X14</th>\n",
              "      <th>X15</th>\n",
              "      <th>X16</th>\n",
              "      <th>X17</th>\n",
              "      <th>X18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C_1</td>\n",
              "      <td>alive</td>\n",
              "      <td>1999</td>\n",
              "      <td>511.267</td>\n",
              "      <td>833.107</td>\n",
              "      <td>18.373</td>\n",
              "      <td>89.031</td>\n",
              "      <td>336.018</td>\n",
              "      <td>35.163</td>\n",
              "      <td>128.348</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.333</td>\n",
              "      <td>740.998</td>\n",
              "      <td>180.447</td>\n",
              "      <td>70.658</td>\n",
              "      <td>191.226</td>\n",
              "      <td>163.816</td>\n",
              "      <td>201.026</td>\n",
              "      <td>1024.333</td>\n",
              "      <td>401.483</td>\n",
              "      <td>935.302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C_1</td>\n",
              "      <td>alive</td>\n",
              "      <td>2000</td>\n",
              "      <td>485.856</td>\n",
              "      <td>713.811</td>\n",
              "      <td>18.577</td>\n",
              "      <td>64.367</td>\n",
              "      <td>320.590</td>\n",
              "      <td>18.531</td>\n",
              "      <td>115.187</td>\n",
              "      <td>...</td>\n",
              "      <td>874.255</td>\n",
              "      <td>701.854</td>\n",
              "      <td>179.987</td>\n",
              "      <td>45.790</td>\n",
              "      <td>160.444</td>\n",
              "      <td>125.392</td>\n",
              "      <td>204.065</td>\n",
              "      <td>874.255</td>\n",
              "      <td>361.642</td>\n",
              "      <td>809.888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C_1</td>\n",
              "      <td>alive</td>\n",
              "      <td>2001</td>\n",
              "      <td>436.656</td>\n",
              "      <td>526.477</td>\n",
              "      <td>22.496</td>\n",
              "      <td>27.207</td>\n",
              "      <td>286.588</td>\n",
              "      <td>-58.939</td>\n",
              "      <td>77.528</td>\n",
              "      <td>...</td>\n",
              "      <td>638.721</td>\n",
              "      <td>710.199</td>\n",
              "      <td>217.699</td>\n",
              "      <td>4.711</td>\n",
              "      <td>112.244</td>\n",
              "      <td>150.464</td>\n",
              "      <td>139.603</td>\n",
              "      <td>638.721</td>\n",
              "      <td>399.964</td>\n",
              "      <td>611.514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C_1</td>\n",
              "      <td>alive</td>\n",
              "      <td>2002</td>\n",
              "      <td>396.412</td>\n",
              "      <td>496.747</td>\n",
              "      <td>27.172</td>\n",
              "      <td>30.745</td>\n",
              "      <td>259.954</td>\n",
              "      <td>-12.410</td>\n",
              "      <td>66.322</td>\n",
              "      <td>...</td>\n",
              "      <td>606.337</td>\n",
              "      <td>686.621</td>\n",
              "      <td>164.658</td>\n",
              "      <td>3.573</td>\n",
              "      <td>109.590</td>\n",
              "      <td>203.575</td>\n",
              "      <td>124.106</td>\n",
              "      <td>606.337</td>\n",
              "      <td>391.633</td>\n",
              "      <td>575.592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C_1</td>\n",
              "      <td>alive</td>\n",
              "      <td>2003</td>\n",
              "      <td>432.204</td>\n",
              "      <td>523.302</td>\n",
              "      <td>26.680</td>\n",
              "      <td>47.491</td>\n",
              "      <td>247.245</td>\n",
              "      <td>3.504</td>\n",
              "      <td>104.661</td>\n",
              "      <td>...</td>\n",
              "      <td>651.958</td>\n",
              "      <td>709.292</td>\n",
              "      <td>248.666</td>\n",
              "      <td>20.811</td>\n",
              "      <td>128.656</td>\n",
              "      <td>131.261</td>\n",
              "      <td>131.884</td>\n",
              "      <td>651.958</td>\n",
              "      <td>407.608</td>\n",
              "      <td>604.467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70568f17-f3ff-482a-8f72-30dbbc89774c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70568f17-f3ff-482a-8f72-30dbbc89774c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70568f17-f3ff-482a-8f72-30dbbc89774c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0548514a-1d99-4859-aab3-f3763917a9bf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0548514a-1d99-4859-aab3-f3763917a9bf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0548514a-1d99-4859-aab3-f3763917a9bf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, roc_auc_score, average_precision_score\n",
        "\n",
        "def find_best_threshold(y_true, y_proba, metric=\"f1\"):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    thresholds = np.linspace(0.01, 0.99, 99)\n",
        "    best_t, best_val = 0.5, -1.0\n",
        "    for t in thresholds:\n",
        "        y_hat = (y_proba >= t).astype(int)\n",
        "        p, r, f1, _ = precision_recall_fscore_support(y_true, y_hat, average=\"binary\", zero_division=0)\n",
        "        val = f1 if metric == \"f1\" else r\n",
        "        if val > best_val:\n",
        "            best_val, best_t = val, t\n",
        "    return float(best_t), float(best_val)\n",
        "\n",
        "def evaluate_at_threshold(y_true, y_proba, threshold):\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp+tn)/cm.sum()\n",
        "    prec = tp/(tp+fp) if (tp+fp) else 0.0\n",
        "    rec  = tp/(tp+fn) if (tp+fn) else 0.0\n",
        "    f1   = 2*prec*rec/(prec+rec) if (prec+rec) else 0.0\n",
        "    return {\"threshold\": float(threshold), \"cm\": cm.tolist(), \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n"
      ],
      "metadata": {
        "id": "3NuG-sBrQREo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 0) เตรียม X, y (map target) =====\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "FEATURES = [\"X8\",\"X17\",\"X3\",\"X11\",\"X10\",\"X1\",\"X6\"]\n",
        "TARGET   = \"status_label\"\n",
        "\n",
        "# ตรวจคอลัมน์\n",
        "missing = [c for c in FEATURES+[TARGET] if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"❌ Missing columns: {missing}\")\n",
        "\n",
        "# y: alive->0, failed->1\n",
        "y = df[TARGET]\n",
        "if y.dtype == object:\n",
        "    y = y.astype(str).str.strip().str.lower().map({\"alive\":0, \"failed\":1}).astype(int)\n",
        "else:\n",
        "    y = pd.Series(y).astype(int)\n",
        "\n",
        "X = df[FEATURES].copy()\n",
        "\n",
        "# ===== 1) split: train/valid/test =====\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_trn, X_val, y_trn, y_val = train_test_split(\n",
        "    X_tr, y_tr, test_size=0.2, random_state=42, stratify=y_tr\n",
        ")\n",
        "\n",
        "# ===== 2) scale_pos_weight จาก train แท้ ๆ =====\n",
        "pos = int((y_trn == 1).sum())\n",
        "neg = int((y_trn == 0).sum())\n",
        "assert pos > 0, \"No positive samples in training set.\"\n",
        "scale_pos_weight = neg / pos\n",
        "\n",
        "print(\"Shapes:\",\n",
        "      \"\\n  X_trn:\", X_trn.shape, \" X_val:\", X_val.shape, \" X_te:\", X_te.shape,\n",
        "      \"\\nClass ratio (train):\", dict(pd.Series(y_trn).value_counts(normalize=True).round(3)))\n",
        "print(f\"scale_pos_weight = {scale_pos_weight:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fQLKPqCSacb",
        "outputId": "23124d58-c0db-4201-d50d-6af6d031129f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: \n",
            "  X_trn: (50356, 7)  X_val: (12589, 7)  X_te: (15737, 7) \n",
            "Class ratio (train): {0: np.float64(0.934), 1: np.float64(0.066)}\n",
            "scale_pos_weight = 14.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ตัวอย่าง time-based split (ปรับช่วงปีตามจริง)\n",
        "train_mask = df[\"year\"] <= 2011\n",
        "val_mask   = (df[\"year\"] >= 2012) & (df[\"year\"] <= 2014)\n",
        "test_mask  = df[\"year\"] >= 2015\n",
        "\n",
        "X_trn, y_trn = X[train_mask], y[train_mask]\n",
        "X_val, y_val = X[val_mask],   y[val_mask]\n",
        "X_te,  y_te  = X[test_mask],  y[test_mask]\n",
        "\n",
        "pos = int((y_trn == 1).sum()); neg = int((y_trn == 0).sum())\n",
        "scale_pos_weight = neg / pos\n",
        "print(\"time-split OK | spw=\", round(scale_pos_weight,2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4R10f7oQS6b",
        "outputId": "ab4fa8e5-a2bb-4157-85a2-c60281e641e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time-split OK | spw= 11.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def fit_xgb_compat(X_trn, y_trn, X_val, y_val, *,\n",
        "                   scale_pos_weight,\n",
        "                   learning_rate=0.03, max_depth=7, min_child_weight=1,\n",
        "                   subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n",
        "                   n_estimators=10000, early_stopping_rounds=300, random_state=42):\n",
        "    params = dict(\n",
        "        objective=\"binary:logistic\",\n",
        "        n_estimators=n_estimators,\n",
        "        learning_rate=learning_rate,\n",
        "        max_depth=max_depth,\n",
        "        min_child_weight=min_child_weight,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        reg_lambda=reg_lambda,\n",
        "        random_state=random_state,\n",
        "        tree_method=\"hist\",\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        eval_metric=\"aucpr\"\n",
        "    )\n",
        "    # try callbacks\n",
        "    try:\n",
        "        model = xgb.XGBClassifier(**params)\n",
        "        model.fit(X_trn, y_trn, eval_set=[(X_val, y_val)], verbose=100,\n",
        "                  callbacks=[xgb.callback.EarlyStopping(rounds=early_stopping_rounds, save_best=True)])\n",
        "        return model\n",
        "    except TypeError:\n",
        "        pass\n",
        "    # try early_stopping_rounds=\n",
        "    try:\n",
        "        model = xgb.XGBClassifier(**params)\n",
        "        model.fit(X_trn, y_trn, eval_set=[(X_val, y_val)], verbose=100,\n",
        "                  early_stopping_rounds=early_stopping_rounds)\n",
        "        return model\n",
        "    except TypeError:\n",
        "        pass\n",
        "    # fallback xgb.train\n",
        "    dtrn = xgb.DMatrix(X_trn, label=y_trn)\n",
        "    dval = xgb.DMatrix(X_val, label=y_val)\n",
        "    train_params = dict(\n",
        "        objective=\"binary:logistic\",\n",
        "        eta=learning_rate,\n",
        "        max_depth=max_depth,\n",
        "        min_child_weight=min_child_weight,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        lambda_=reg_lambda,\n",
        "        tree_method=\"hist\",\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        eval_metric=\"aucpr\",\n",
        "        seed=random_state,\n",
        "    )\n",
        "    booster = xgb.train(train_params, dtrn, num_boost_round=n_estimators,\n",
        "                        evals=[(dtrn,\"train\"),(dval,\"valid\")],\n",
        "                        early_stopping_rounds=early_stopping_rounds, verbose_eval=100)\n",
        "    class BoosterWrapper:\n",
        "        def __init__(self, booster): self.booster = booster\n",
        "        def predict_proba(self, X):\n",
        "            dm = xgb.DMatrix(X)\n",
        "            best_it = getattr(self.booster, \"best_iteration\", None)\n",
        "            p = self.booster.predict(dm, iteration_range=(0, best_it+1)) if best_it is not None else self.booster.predict(dm)\n",
        "            import numpy as np\n",
        "            return np.vstack([1-p, p]).T\n",
        "    return BoosterWrapper(booster)\n"
      ],
      "metadata": {
        "id": "4ix9H13DQUBq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "def fit_lgbm(X_trn, y_trn, X_val, y_val, *,\n",
        "             scale_pos_weight,\n",
        "             num_leaves=63, min_child_samples=100,\n",
        "             learning_rate=0.03, subsample=0.8, colsample_bytree=0.8,\n",
        "             reg_lambda=1.0, n_estimators=10000, early_stopping_rounds=300, random_state=42):\n",
        "    lgbm = lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        n_estimators=n_estimators,\n",
        "        learning_rate=learning_rate,\n",
        "        num_leaves=num_leaves,\n",
        "        min_child_samples=min_child_samples,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        reg_lambda=reg_lambda,\n",
        "        random_state=random_state,\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        first_metric_only=True,\n",
        "        force_col_wise=True\n",
        "    )\n",
        "    lgbm.fit(\n",
        "        X_trn, y_trn,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric=\"average_precision\",\n",
        "        callbacks=[lgb.early_stopping(early_stopping_rounds), lgb.log_evaluation(100)]\n",
        "    )\n",
        "    return lgbm\n"
      ],
      "metadata": {
        "id": "RMr68b_IQWay"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "# กริดเล็กๆ พอให้วิ่งเร็ว\n",
        "spw_mults_lgb = [0.5, 1.0, 2.0, 4.0]\n",
        "leaves_grid   = [31, 63, 127]\n",
        "mcs_grid      = [50, 200]          # min_child_samples\n",
        "lr_grid       = [0.02, 0.05]\n",
        "col_grid      = [0.7, 0.9]\n",
        "sub_grid      = [0.7, 0.9]\n",
        "\n",
        "spw_mults_xgb = [0.5, 1.0, 2.0, 4.0]\n",
        "md_grid       = [4, 7]             # max_depth\n",
        "mcw_grid      = [1, 5]             # min_child_weight\n",
        "lr_x_grid     = [0.02, 0.05]\n",
        "col_x_grid    = [0.7, 0.9]\n",
        "sub_x_grid    = [0.7, 0.9]\n",
        "\n",
        "results = []\n",
        "\n",
        "# ---- LightGBM sweep ----\n",
        "for spwm, nl, mcs, lr, col, sub in product(spw_mults_lgb, leaves_grid, mcs_grid, lr_grid, col_grid, sub_grid):\n",
        "    try:\n",
        "        model = fit_lgbm(\n",
        "            X_trn, y_trn, X_val, y_val,\n",
        "            scale_pos_weight=spw_base*spwm,\n",
        "            num_leaves=nl, min_child_samples=mcs,\n",
        "            learning_rate=lr, colsample_bytree=col, subsample=sub,\n",
        "            early_stopping_rounds=200\n",
        "        )\n",
        "        proba_val = model.predict_proba(X_val)[:,1]\n",
        "        t_val, f1_val = find_best_threshold(y_val, proba_val, metric=\"f1\")\n",
        "        auprc_val = average_precision_score(y_val, proba_val)\n",
        "        results.append({\n",
        "            \"model\":\"LGBM\",\"params\":{\"spw_mult\":spwm,\"num_leaves\":nl,\"min_child_samples\":mcs,\"lr\":lr,\"col\":col,\"sub\":sub},\n",
        "            \"t_val\":t_val, \"f1_val\":f1_val, \"auprc_val\":auprc_val, \"estimator\":model\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(\"LGBM fail:\", e)\n",
        "\n",
        "# ---- XGBoost sweep ----\n",
        "for spwm, md, mcw, lr, col, sub in product(spw_mults_xgb, md_grid, mcw_grid, lr_x_grid, col_x_grid, sub_x_grid):\n",
        "    try:\n",
        "        model = fit_xgb_compat(\n",
        "            X_trn, y_trn, X_val, y_val,\n",
        "            scale_pos_weight=spw_base*spwm,\n",
        "            learning_rate=lr, max_depth=md, min_child_weight=mcw,\n",
        "            colsample_bytree=col, subsample=sub,\n",
        "            early_stopping_rounds=200\n",
        "        )\n",
        "        proba_val = model.predict_proba(X_val)[:,1]\n",
        "        t_val, f1_val = find_best_threshold(y_val, proba_val, metric=\"f1\")\n",
        "        auprc_val = average_precision_score(y_val, proba_val)\n",
        "        results.append({\n",
        "            \"model\":\"XGB\",\"params\":{\"spw_mult\":spwm,\"max_depth\":md,\"min_child_weight\":mcw,\"lr\":lr,\"col\":col,\"sub\":sub},\n",
        "            \"t_val\":t_val, \"f1_val\":f1_val, \"auprc_val\":auprc_val, \"estimator\":model\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(\"XGB fail:\", e)\n",
        "\n",
        "# ตารางสรุป (เรียงตาม F1 บน validation)\n",
        "df_res = pd.DataFrame(results).sort_values([\"f1_val\",\"auprc_val\"], ascending=False)\n",
        "print(df_res[[\"model\",\"params\",\"t_val\",\"f1_val\",\"auprc_val\"]].head(10))\n",
        "best = df_res.iloc[0]\n",
        "best_model = best[\"estimator\"]\n",
        "best_t = float(best[\"t_val\"])\n",
        "print(\"\\nBest candidate:\", best[\"model\"], best[\"params\"], \"t*=\", best_t, \"F1_val=\", round(best[\"f1_val\"],4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpUVsxbqQYXk",
        "outputId": "73bcc9c0-ea43-4198-a72f-8503d7a90867"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.256831\tvalid_0's binary_logloss: 0.367382\n",
            "[200]\tvalid_0's average_precision: 0.255301\tvalid_0's binary_logloss: 0.394631\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107647\tvalid_0's binary_logloss: 0.198711\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.256831\tvalid_0's binary_logloss: 0.367382\n",
            "[200]\tvalid_0's average_precision: 0.255301\tvalid_0's binary_logloss: 0.394631\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107647\tvalid_0's binary_logloss: 0.198711\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.259529\tvalid_0's binary_logloss: 0.368357\n",
            "[200]\tvalid_0's average_precision: 0.265561\tvalid_0's binary_logloss: 0.39379\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132\tvalid_0's binary_logloss: 0.198484\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.259529\tvalid_0's binary_logloss: 0.368357\n",
            "[200]\tvalid_0's average_precision: 0.265561\tvalid_0's binary_logloss: 0.39379\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132\tvalid_0's binary_logloss: 0.198484\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.247642\tvalid_0's binary_logloss: 0.393289\n",
            "[200]\tvalid_0's average_precision: 0.246664\tvalid_0's binary_logloss: 0.377304\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107647\tvalid_0's binary_logloss: 0.201374\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.247642\tvalid_0's binary_logloss: 0.393289\n",
            "[200]\tvalid_0's average_precision: 0.246664\tvalid_0's binary_logloss: 0.377304\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107647\tvalid_0's binary_logloss: 0.201374\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.253142\tvalid_0's binary_logloss: 0.393889\n",
            "[200]\tvalid_0's average_precision: 0.245191\tvalid_0's binary_logloss: 0.377554\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132\tvalid_0's binary_logloss: 0.200797\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.253142\tvalid_0's binary_logloss: 0.393889\n",
            "[200]\tvalid_0's average_precision: 0.245191\tvalid_0's binary_logloss: 0.377554\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132\tvalid_0's binary_logloss: 0.200797\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.248725\tvalid_0's binary_logloss: 0.369264\n",
            "[200]\tvalid_0's average_precision: 0.253203\tvalid_0's binary_logloss: 0.398096\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107647\tvalid_0's binary_logloss: 0.198711\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.248725\tvalid_0's binary_logloss: 0.369264\n",
            "[200]\tvalid_0's average_precision: 0.253203\tvalid_0's binary_logloss: 0.398096\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107647\tvalid_0's binary_logloss: 0.198711\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25068\tvalid_0's binary_logloss: 0.370399\n",
            "[200]\tvalid_0's average_precision: 0.255726\tvalid_0's binary_logloss: 0.397305\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132\tvalid_0's binary_logloss: 0.198484\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25068\tvalid_0's binary_logloss: 0.370399\n",
            "[200]\tvalid_0's average_precision: 0.255726\tvalid_0's binary_logloss: 0.397305\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132\tvalid_0's binary_logloss: 0.198484\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.256969\tvalid_0's binary_logloss: 0.397552\n",
            "[200]\tvalid_0's average_precision: 0.25194\tvalid_0's binary_logloss: 0.384758\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107647\tvalid_0's binary_logloss: 0.201374\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.256969\tvalid_0's binary_logloss: 0.397552\n",
            "[200]\tvalid_0's average_precision: 0.25194\tvalid_0's binary_logloss: 0.384758\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107647\tvalid_0's binary_logloss: 0.201374\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.252333\tvalid_0's binary_logloss: 0.397519\n",
            "[200]\tvalid_0's average_precision: 0.235946\tvalid_0's binary_logloss: 0.384599\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132\tvalid_0's binary_logloss: 0.200797\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.252333\tvalid_0's binary_logloss: 0.397519\n",
            "[200]\tvalid_0's average_precision: 0.235946\tvalid_0's binary_logloss: 0.384599\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132\tvalid_0's binary_logloss: 0.200797\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.249487\tvalid_0's binary_logloss: 0.354147\n",
            "[200]\tvalid_0's average_precision: 0.252975\tvalid_0's binary_logloss: 0.374683\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105153\tvalid_0's binary_logloss: 0.198522\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.249487\tvalid_0's binary_logloss: 0.354147\n",
            "[200]\tvalid_0's average_precision: 0.252975\tvalid_0's binary_logloss: 0.374683\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105153\tvalid_0's binary_logloss: 0.198522\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.243039\tvalid_0's binary_logloss: 0.355048\n",
            "[200]\tvalid_0's average_precision: 0.249966\tvalid_0's binary_logloss: 0.374876\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.135505\tvalid_0's binary_logloss: 0.198133\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.243039\tvalid_0's binary_logloss: 0.355048\n",
            "[200]\tvalid_0's average_precision: 0.249966\tvalid_0's binary_logloss: 0.374876\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.135505\tvalid_0's binary_logloss: 0.198133\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.236295\tvalid_0's binary_logloss: 0.373304\n",
            "[200]\tvalid_0's average_precision: 0.224679\tvalid_0's binary_logloss: 0.349053\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105153\tvalid_0's binary_logloss: 0.200921\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.236295\tvalid_0's binary_logloss: 0.373304\n",
            "[200]\tvalid_0's average_precision: 0.224679\tvalid_0's binary_logloss: 0.349053\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105153\tvalid_0's binary_logloss: 0.200921\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.239775\tvalid_0's binary_logloss: 0.370159\n",
            "[200]\tvalid_0's average_precision: 0.230118\tvalid_0's binary_logloss: 0.344057\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.135505\tvalid_0's binary_logloss: 0.19992\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.239775\tvalid_0's binary_logloss: 0.370159\n",
            "[200]\tvalid_0's average_precision: 0.230118\tvalid_0's binary_logloss: 0.344057\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.135505\tvalid_0's binary_logloss: 0.19992\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.246786\tvalid_0's binary_logloss: 0.357814\n",
            "[200]\tvalid_0's average_precision: 0.243326\tvalid_0's binary_logloss: 0.381685\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.108253\tvalid_0's binary_logloss: 0.198496\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.246786\tvalid_0's binary_logloss: 0.357814\n",
            "[200]\tvalid_0's average_precision: 0.243326\tvalid_0's binary_logloss: 0.381685\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.108253\tvalid_0's binary_logloss: 0.198496\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.23682\tvalid_0's binary_logloss: 0.35804\n",
            "[200]\tvalid_0's average_precision: 0.245604\tvalid_0's binary_logloss: 0.380016\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.133999\tvalid_0's binary_logloss: 0.198204\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.23682\tvalid_0's binary_logloss: 0.35804\n",
            "[200]\tvalid_0's average_precision: 0.245604\tvalid_0's binary_logloss: 0.380016\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.133999\tvalid_0's binary_logloss: 0.198204\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241785\tvalid_0's binary_logloss: 0.379374\n",
            "[200]\tvalid_0's average_precision: 0.23421\tvalid_0's binary_logloss: 0.360135\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.108253\tvalid_0's binary_logloss: 0.200845\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241785\tvalid_0's binary_logloss: 0.379374\n",
            "[200]\tvalid_0's average_precision: 0.23421\tvalid_0's binary_logloss: 0.360135\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.108253\tvalid_0's binary_logloss: 0.200845\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241979\tvalid_0's binary_logloss: 0.379506\n",
            "[200]\tvalid_0's average_precision: 0.224835\tvalid_0's binary_logloss: 0.35882\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.133999\tvalid_0's binary_logloss: 0.200105\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241979\tvalid_0's binary_logloss: 0.379506\n",
            "[200]\tvalid_0's average_precision: 0.224835\tvalid_0's binary_logloss: 0.35882\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.133999\tvalid_0's binary_logloss: 0.200105\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.242358\tvalid_0's binary_logloss: 0.335016\n",
            "[200]\tvalid_0's average_precision: 0.235326\tvalid_0's binary_logloss: 0.346696\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103927\tvalid_0's binary_logloss: 0.198267\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.242358\tvalid_0's binary_logloss: 0.335016\n",
            "[200]\tvalid_0's average_precision: 0.235326\tvalid_0's binary_logloss: 0.346696\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103927\tvalid_0's binary_logloss: 0.198267\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.245547\tvalid_0's binary_logloss: 0.33582\n",
            "[200]\tvalid_0's average_precision: 0.239342\tvalid_0's binary_logloss: 0.345083\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.137473\tvalid_0's binary_logloss: 0.197881\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.245547\tvalid_0's binary_logloss: 0.33582\n",
            "[200]\tvalid_0's average_precision: 0.239342\tvalid_0's binary_logloss: 0.345083\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.137473\tvalid_0's binary_logloss: 0.197881\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.223164\tvalid_0's binary_logloss: 0.340312\n",
            "[200]\tvalid_0's average_precision: 0.212956\tvalid_0's binary_logloss: 0.304865\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103927\tvalid_0's binary_logloss: 0.200305\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.223164\tvalid_0's binary_logloss: 0.340312\n",
            "[200]\tvalid_0's average_precision: 0.212956\tvalid_0's binary_logloss: 0.304865\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103927\tvalid_0's binary_logloss: 0.200305\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.238412\tvalid_0's binary_logloss: 0.339598\n",
            "[200]\tvalid_0's average_precision: 0.218247\tvalid_0's binary_logloss: 0.301965\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.137473\tvalid_0's binary_logloss: 0.199316\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.238412\tvalid_0's binary_logloss: 0.339598\n",
            "[200]\tvalid_0's average_precision: 0.218247\tvalid_0's binary_logloss: 0.301965\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.137473\tvalid_0's binary_logloss: 0.199316\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241232\tvalid_0's binary_logloss: 0.343003\n",
            "[200]\tvalid_0's average_precision: 0.243497\tvalid_0's binary_logloss: 0.359926\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.10793\tvalid_0's binary_logloss: 0.198311\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241232\tvalid_0's binary_logloss: 0.343003\n",
            "[200]\tvalid_0's average_precision: 0.243497\tvalid_0's binary_logloss: 0.359926\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.10793\tvalid_0's binary_logloss: 0.198311\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.23666\tvalid_0's binary_logloss: 0.34228\n",
            "[200]\tvalid_0's average_precision: 0.23811\tvalid_0's binary_logloss: 0.357606\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.135185\tvalid_0's binary_logloss: 0.197967\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.23666\tvalid_0's binary_logloss: 0.34228\n",
            "[200]\tvalid_0's average_precision: 0.23811\tvalid_0's binary_logloss: 0.357606\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.135185\tvalid_0's binary_logloss: 0.197967\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.22793\tvalid_0's binary_logloss: 0.354827\n",
            "[200]\tvalid_0's average_precision: 0.20312\tvalid_0's binary_logloss: 0.32887\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.10793\tvalid_0's binary_logloss: 0.200412\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.22793\tvalid_0's binary_logloss: 0.354827\n",
            "[200]\tvalid_0's average_precision: 0.20312\tvalid_0's binary_logloss: 0.32887\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.10793\tvalid_0's binary_logloss: 0.200412\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.231877\tvalid_0's binary_logloss: 0.355005\n",
            "[200]\tvalid_0's average_precision: 0.21488\tvalid_0's binary_logloss: 0.327245\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.135185\tvalid_0's binary_logloss: 0.199532\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.231877\tvalid_0's binary_logloss: 0.355005\n",
            "[200]\tvalid_0's average_precision: 0.21488\tvalid_0's binary_logloss: 0.327245\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.135185\tvalid_0's binary_logloss: 0.199532\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.254752\tvalid_0's binary_logloss: 0.541294\n",
            "[200]\tvalid_0's average_precision: 0.25337\tvalid_0's binary_logloss: 0.602879\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107257\tvalid_0's binary_logloss: 0.200152\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.254752\tvalid_0's binary_logloss: 0.541294\n",
            "[200]\tvalid_0's average_precision: 0.25337\tvalid_0's binary_logloss: 0.602879\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107257\tvalid_0's binary_logloss: 0.200152\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.258242\tvalid_0's binary_logloss: 0.543662\n",
            "[200]\tvalid_0's average_precision: 0.26087\tvalid_0's binary_logloss: 0.601275\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116314\tvalid_0's binary_logloss: 0.199916\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.258242\tvalid_0's binary_logloss: 0.543662\n",
            "[200]\tvalid_0's average_precision: 0.26087\tvalid_0's binary_logloss: 0.601275\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116314\tvalid_0's binary_logloss: 0.199916\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.246774\tvalid_0's binary_logloss: 0.601271\n",
            "[200]\tvalid_0's average_precision: 0.245456\tvalid_0's binary_logloss: 0.565667\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107257\tvalid_0's binary_logloss: 0.206267\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.246774\tvalid_0's binary_logloss: 0.601271\n",
            "[200]\tvalid_0's average_precision: 0.245456\tvalid_0's binary_logloss: 0.565667\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107257\tvalid_0's binary_logloss: 0.206267\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.257831\tvalid_0's binary_logloss: 0.600053\n",
            "[200]\tvalid_0's average_precision: 0.242076\tvalid_0's binary_logloss: 0.565684\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116314\tvalid_0's binary_logloss: 0.205666\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.257831\tvalid_0's binary_logloss: 0.600053\n",
            "[200]\tvalid_0's average_precision: 0.242076\tvalid_0's binary_logloss: 0.565684\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116314\tvalid_0's binary_logloss: 0.205666\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.251325\tvalid_0's binary_logloss: 0.545337\n",
            "[200]\tvalid_0's average_precision: 0.247319\tvalid_0's binary_logloss: 0.608984\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.121205\tvalid_0's binary_logloss: 0.200116\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.251325\tvalid_0's binary_logloss: 0.545337\n",
            "[200]\tvalid_0's average_precision: 0.247319\tvalid_0's binary_logloss: 0.608984\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.121205\tvalid_0's binary_logloss: 0.200116\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.249447\tvalid_0's binary_logloss: 0.546549\n",
            "[200]\tvalid_0's average_precision: 0.253382\tvalid_0's binary_logloss: 0.607779\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.113234\tvalid_0's binary_logloss: 0.199906\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.249447\tvalid_0's binary_logloss: 0.546549\n",
            "[200]\tvalid_0's average_precision: 0.253382\tvalid_0's binary_logloss: 0.607779\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.113234\tvalid_0's binary_logloss: 0.199906\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.245437\tvalid_0's binary_logloss: 0.608166\n",
            "[200]\tvalid_0's average_precision: 0.247262\tvalid_0's binary_logloss: 0.581087\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.121205\tvalid_0's binary_logloss: 0.206183\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.245437\tvalid_0's binary_logloss: 0.608166\n",
            "[200]\tvalid_0's average_precision: 0.247262\tvalid_0's binary_logloss: 0.581087\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.121205\tvalid_0's binary_logloss: 0.206183\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25042\tvalid_0's binary_logloss: 0.608353\n",
            "[200]\tvalid_0's average_precision: 0.243664\tvalid_0's binary_logloss: 0.578454\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.113234\tvalid_0's binary_logloss: 0.205643\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25042\tvalid_0's binary_logloss: 0.608353\n",
            "[200]\tvalid_0's average_precision: 0.243664\tvalid_0's binary_logloss: 0.578454\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.113234\tvalid_0's binary_logloss: 0.205643\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.24996\tvalid_0's binary_logloss: 0.513788\n",
            "[200]\tvalid_0's average_precision: 0.251326\tvalid_0's binary_logloss: 0.560976\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105757\tvalid_0's binary_logloss: 0.199784\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.24996\tvalid_0's binary_logloss: 0.513788\n",
            "[200]\tvalid_0's average_precision: 0.251326\tvalid_0's binary_logloss: 0.560976\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105757\tvalid_0's binary_logloss: 0.199784\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.248363\tvalid_0's binary_logloss: 0.516167\n",
            "[200]\tvalid_0's average_precision: 0.253356\tvalid_0's binary_logloss: 0.561487\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.131685\tvalid_0's binary_logloss: 0.199533\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.248363\tvalid_0's binary_logloss: 0.516167\n",
            "[200]\tvalid_0's average_precision: 0.253356\tvalid_0's binary_logloss: 0.561487\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.131685\tvalid_0's binary_logloss: 0.199533\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.234355\tvalid_0's binary_logloss: 0.555008\n",
            "[200]\tvalid_0's average_precision: 0.224828\tvalid_0's binary_logloss: 0.502041\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105757\tvalid_0's binary_logloss: 0.205362\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.234355\tvalid_0's binary_logloss: 0.555008\n",
            "[200]\tvalid_0's average_precision: 0.224828\tvalid_0's binary_logloss: 0.502041\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105757\tvalid_0's binary_logloss: 0.205362\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.24886\tvalid_0's binary_logloss: 0.552224\n",
            "[200]\tvalid_0's average_precision: 0.229214\tvalid_0's binary_logloss: 0.499297\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.131685\tvalid_0's binary_logloss: 0.204666\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.24886\tvalid_0's binary_logloss: 0.552224\n",
            "[200]\tvalid_0's average_precision: 0.229214\tvalid_0's binary_logloss: 0.499297\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.131685\tvalid_0's binary_logloss: 0.204666\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.247415\tvalid_0's binary_logloss: 0.520011\n",
            "[200]\tvalid_0's average_precision: 0.241391\tvalid_0's binary_logloss: 0.57239\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105692\tvalid_0's binary_logloss: 0.199882\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.247415\tvalid_0's binary_logloss: 0.520011\n",
            "[200]\tvalid_0's average_precision: 0.241391\tvalid_0's binary_logloss: 0.57239\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105692\tvalid_0's binary_logloss: 0.199882\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.244677\tvalid_0's binary_logloss: 0.521054\n",
            "[200]\tvalid_0's average_precision: 0.246015\tvalid_0's binary_logloss: 0.571065\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.12878\tvalid_0's binary_logloss: 0.199629\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.244677\tvalid_0's binary_logloss: 0.521054\n",
            "[200]\tvalid_0's average_precision: 0.246015\tvalid_0's binary_logloss: 0.571065\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.12878\tvalid_0's binary_logloss: 0.199629\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.253216\tvalid_0's binary_logloss: 0.57025\n",
            "[200]\tvalid_0's average_precision: 0.233176\tvalid_0's binary_logloss: 0.52928\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105692\tvalid_0's binary_logloss: 0.205608\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.253216\tvalid_0's binary_logloss: 0.57025\n",
            "[200]\tvalid_0's average_precision: 0.233176\tvalid_0's binary_logloss: 0.52928\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105692\tvalid_0's binary_logloss: 0.205608\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25307\tvalid_0's binary_logloss: 0.56819\n",
            "[200]\tvalid_0's average_precision: 0.236497\tvalid_0's binary_logloss: 0.522758\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.12878\tvalid_0's binary_logloss: 0.20491\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25307\tvalid_0's binary_logloss: 0.56819\n",
            "[200]\tvalid_0's average_precision: 0.236497\tvalid_0's binary_logloss: 0.522758\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.12878\tvalid_0's binary_logloss: 0.20491\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.246223\tvalid_0's binary_logloss: 0.474945\n",
            "[200]\tvalid_0's average_precision: 0.241015\tvalid_0's binary_logloss: 0.502476\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.104425\tvalid_0's binary_logloss: 0.19943\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.246223\tvalid_0's binary_logloss: 0.474945\n",
            "[200]\tvalid_0's average_precision: 0.241015\tvalid_0's binary_logloss: 0.502476\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.104425\tvalid_0's binary_logloss: 0.19943\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.253825\tvalid_0's binary_logloss: 0.475865\n",
            "[200]\tvalid_0's average_precision: 0.249482\tvalid_0's binary_logloss: 0.500906\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.130401\tvalid_0's binary_logloss: 0.19906\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.253825\tvalid_0's binary_logloss: 0.475865\n",
            "[200]\tvalid_0's average_precision: 0.249482\tvalid_0's binary_logloss: 0.500906\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.130401\tvalid_0's binary_logloss: 0.19906\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.229378\tvalid_0's binary_logloss: 0.491482\n",
            "[200]\tvalid_0's average_precision: 0.214721\tvalid_0's binary_logloss: 0.421626\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.104425\tvalid_0's binary_logloss: 0.204466\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.229378\tvalid_0's binary_logloss: 0.491482\n",
            "[200]\tvalid_0's average_precision: 0.214721\tvalid_0's binary_logloss: 0.421626\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.104425\tvalid_0's binary_logloss: 0.204466\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.237695\tvalid_0's binary_logloss: 0.486488\n",
            "[200]\tvalid_0's average_precision: 0.214022\tvalid_0's binary_logloss: 0.416646\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.130401\tvalid_0's binary_logloss: 0.203467\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.237695\tvalid_0's binary_logloss: 0.486488\n",
            "[200]\tvalid_0's average_precision: 0.214022\tvalid_0's binary_logloss: 0.416646\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.130401\tvalid_0's binary_logloss: 0.203467\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.24\tvalid_0's binary_logloss: 0.489449\n",
            "[200]\tvalid_0's average_precision: 0.235033\tvalid_0's binary_logloss: 0.528664\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103456\tvalid_0's binary_logloss: 0.199673\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.24\tvalid_0's binary_logloss: 0.489449\n",
            "[200]\tvalid_0's average_precision: 0.235033\tvalid_0's binary_logloss: 0.528664\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103456\tvalid_0's binary_logloss: 0.199673\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.237982\tvalid_0's binary_logloss: 0.487092\n",
            "[200]\tvalid_0's average_precision: 0.240206\tvalid_0's binary_logloss: 0.523777\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132416\tvalid_0's binary_logloss: 0.199183\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.237982\tvalid_0's binary_logloss: 0.487092\n",
            "[200]\tvalid_0's average_precision: 0.240206\tvalid_0's binary_logloss: 0.523777\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132416\tvalid_0's binary_logloss: 0.199183\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.228102\tvalid_0's binary_logloss: 0.520327\n",
            "[200]\tvalid_0's average_precision: 0.216217\tvalid_0's binary_logloss: 0.466178\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103456\tvalid_0's binary_logloss: 0.205048\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.228102\tvalid_0's binary_logloss: 0.520327\n",
            "[200]\tvalid_0's average_precision: 0.216217\tvalid_0's binary_logloss: 0.466178\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103456\tvalid_0's binary_logloss: 0.205048\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.24328\tvalid_0's binary_logloss: 0.517627\n",
            "[200]\tvalid_0's average_precision: 0.220282\tvalid_0's binary_logloss: 0.461486\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132416\tvalid_0's binary_logloss: 0.203793\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.24328\tvalid_0's binary_logloss: 0.517627\n",
            "[200]\tvalid_0's average_precision: 0.220282\tvalid_0's binary_logloss: 0.461486\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.132416\tvalid_0's binary_logloss: 0.203793\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.254652\tvalid_0's binary_logloss: 0.768916\n",
            "[200]\tvalid_0's average_precision: 0.251667\tvalid_0's binary_logloss: 0.890756\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105275\tvalid_0's binary_logloss: 0.201853\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.254652\tvalid_0's binary_logloss: 0.768916\n",
            "[200]\tvalid_0's average_precision: 0.251667\tvalid_0's binary_logloss: 0.890756\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105275\tvalid_0's binary_logloss: 0.201853\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.22418\tvalid_0's binary_logloss: 0.771642\n",
            "[200]\tvalid_0's average_precision: 0.257058\tvalid_0's binary_logloss: 0.88874\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.114396\tvalid_0's binary_logloss: 0.201793\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.22418\tvalid_0's binary_logloss: 0.771642\n",
            "[200]\tvalid_0's average_precision: 0.257058\tvalid_0's binary_logloss: 0.88874\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.114396\tvalid_0's binary_logloss: 0.201793\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.258774\tvalid_0's binary_logloss: 0.886332\n",
            "[200]\tvalid_0's average_precision: 0.249699\tvalid_0's binary_logloss: 0.820233\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105275\tvalid_0's binary_logloss: 0.212362\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.258774\tvalid_0's binary_logloss: 0.886332\n",
            "[200]\tvalid_0's average_precision: 0.249699\tvalid_0's binary_logloss: 0.820233\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105275\tvalid_0's binary_logloss: 0.212362\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.256275\tvalid_0's binary_logloss: 0.888721\n",
            "[200]\tvalid_0's average_precision: 0.24526\tvalid_0's binary_logloss: 0.820294\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.114396\tvalid_0's binary_logloss: 0.212164\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.256275\tvalid_0's binary_logloss: 0.888721\n",
            "[200]\tvalid_0's average_precision: 0.24526\tvalid_0's binary_logloss: 0.820294\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.114396\tvalid_0's binary_logloss: 0.212164\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25023\tvalid_0's binary_logloss: 0.774102\n",
            "[200]\tvalid_0's average_precision: 0.246969\tvalid_0's binary_logloss: 0.902008\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105516\tvalid_0's binary_logloss: 0.201949\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25023\tvalid_0's binary_logloss: 0.774102\n",
            "[200]\tvalid_0's average_precision: 0.246969\tvalid_0's binary_logloss: 0.902008\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105516\tvalid_0's binary_logloss: 0.201949\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.237045\tvalid_0's binary_logloss: 0.776028\n",
            "[200]\tvalid_0's average_precision: 0.252666\tvalid_0's binary_logloss: 0.901427\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.109223\tvalid_0's binary_logloss: 0.201904\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.237045\tvalid_0's binary_logloss: 0.776028\n",
            "[200]\tvalid_0's average_precision: 0.252666\tvalid_0's binary_logloss: 0.901427\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.109223\tvalid_0's binary_logloss: 0.201904\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.252362\tvalid_0's binary_logloss: 0.902614\n",
            "[200]\tvalid_0's average_precision: 0.250219\tvalid_0's binary_logloss: 0.85016\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105516\tvalid_0's binary_logloss: 0.212617\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.252362\tvalid_0's binary_logloss: 0.902614\n",
            "[200]\tvalid_0's average_precision: 0.250219\tvalid_0's binary_logloss: 0.85016\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105516\tvalid_0's binary_logloss: 0.212617\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.250712\tvalid_0's binary_logloss: 0.902516\n",
            "[200]\tvalid_0's average_precision: 0.247991\tvalid_0's binary_logloss: 0.847024\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.109223\tvalid_0's binary_logloss: 0.212437\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.250712\tvalid_0's binary_logloss: 0.902516\n",
            "[200]\tvalid_0's average_precision: 0.247991\tvalid_0's binary_logloss: 0.847024\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.109223\tvalid_0's binary_logloss: 0.212437\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.257884\tvalid_0's binary_logloss: 0.720419\n",
            "[200]\tvalid_0's average_precision: 0.247479\tvalid_0's binary_logloss: 0.815472\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107409\tvalid_0's binary_logloss: 0.20142\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.257884\tvalid_0's binary_logloss: 0.720419\n",
            "[200]\tvalid_0's average_precision: 0.247479\tvalid_0's binary_logloss: 0.815472\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107409\tvalid_0's binary_logloss: 0.20142\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241538\tvalid_0's binary_logloss: 0.719881\n",
            "[200]\tvalid_0's average_precision: 0.246176\tvalid_0's binary_logloss: 0.812642\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116014\tvalid_0's binary_logloss: 0.201292\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241538\tvalid_0's binary_logloss: 0.719881\n",
            "[200]\tvalid_0's average_precision: 0.246176\tvalid_0's binary_logloss: 0.812642\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116014\tvalid_0's binary_logloss: 0.201292\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.251646\tvalid_0's binary_logloss: 0.803289\n",
            "[200]\tvalid_0's average_precision: 0.234392\tvalid_0's binary_logloss: 0.706027\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107409\tvalid_0's binary_logloss: 0.211237\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.251646\tvalid_0's binary_logloss: 0.803289\n",
            "[200]\tvalid_0's average_precision: 0.234392\tvalid_0's binary_logloss: 0.706027\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107409\tvalid_0's binary_logloss: 0.211237\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.252017\tvalid_0's binary_logloss: 0.796459\n",
            "[200]\tvalid_0's average_precision: 0.230249\tvalid_0's binary_logloss: 0.699612\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116014\tvalid_0's binary_logloss: 0.210846\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.252017\tvalid_0's binary_logloss: 0.796459\n",
            "[200]\tvalid_0's average_precision: 0.230249\tvalid_0's binary_logloss: 0.699612\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116014\tvalid_0's binary_logloss: 0.210846\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.257756\tvalid_0's binary_logloss: 0.731793\n",
            "[200]\tvalid_0's average_precision: 0.246444\tvalid_0's binary_logloss: 0.839428\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107292\tvalid_0's binary_logloss: 0.201605\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.257756\tvalid_0's binary_logloss: 0.731793\n",
            "[200]\tvalid_0's average_precision: 0.246444\tvalid_0's binary_logloss: 0.839428\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107292\tvalid_0's binary_logloss: 0.201605\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25044\tvalid_0's binary_logloss: 0.731409\n",
            "[200]\tvalid_0's average_precision: 0.244657\tvalid_0's binary_logloss: 0.838057\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.113483\tvalid_0's binary_logloss: 0.201423\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25044\tvalid_0's binary_logloss: 0.731409\n",
            "[200]\tvalid_0's average_precision: 0.244657\tvalid_0's binary_logloss: 0.838057\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.113483\tvalid_0's binary_logloss: 0.201423\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.238616\tvalid_0's binary_logloss: 0.834829\n",
            "[200]\tvalid_0's average_precision: 0.230435\tvalid_0's binary_logloss: 0.760407\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107292\tvalid_0's binary_logloss: 0.211673\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.238616\tvalid_0's binary_logloss: 0.834829\n",
            "[200]\tvalid_0's average_precision: 0.230435\tvalid_0's binary_logloss: 0.760407\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.107292\tvalid_0's binary_logloss: 0.211673\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.243425\tvalid_0's binary_logloss: 0.832033\n",
            "[200]\tvalid_0's average_precision: 0.235369\tvalid_0's binary_logloss: 0.751834\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.113483\tvalid_0's binary_logloss: 0.211139\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.243425\tvalid_0's binary_logloss: 0.832033\n",
            "[200]\tvalid_0's average_precision: 0.235369\tvalid_0's binary_logloss: 0.751834\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.113483\tvalid_0's binary_logloss: 0.211139\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.259403\tvalid_0's binary_logloss: 0.652112\n",
            "[200]\tvalid_0's average_precision: 0.243872\tvalid_0's binary_logloss: 0.713655\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116885\tvalid_0's binary_logloss: 0.201025\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.259403\tvalid_0's binary_logloss: 0.652112\n",
            "[200]\tvalid_0's average_precision: 0.243872\tvalid_0's binary_logloss: 0.713655\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116885\tvalid_0's binary_logloss: 0.201025\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.251809\tvalid_0's binary_logloss: 0.650665\n",
            "[200]\tvalid_0's average_precision: 0.238411\tvalid_0's binary_logloss: 0.707976\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.119363\tvalid_0's binary_logloss: 0.200616\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.251809\tvalid_0's binary_logloss: 0.650665\n",
            "[200]\tvalid_0's average_precision: 0.238411\tvalid_0's binary_logloss: 0.707976\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.119363\tvalid_0's binary_logloss: 0.200616\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.223305\tvalid_0's binary_logloss: 0.692535\n",
            "[200]\tvalid_0's average_precision: 0.20958\tvalid_0's binary_logloss: 0.570663\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116885\tvalid_0's binary_logloss: 0.210172\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.223305\tvalid_0's binary_logloss: 0.692535\n",
            "[200]\tvalid_0's average_precision: 0.20958\tvalid_0's binary_logloss: 0.570663\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.116885\tvalid_0's binary_logloss: 0.210172\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.238388\tvalid_0's binary_logloss: 0.682027\n",
            "[200]\tvalid_0's average_precision: 0.218741\tvalid_0's binary_logloss: 0.556522\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.119363\tvalid_0's binary_logloss: 0.209088\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.238388\tvalid_0's binary_logloss: 0.682027\n",
            "[200]\tvalid_0's average_precision: 0.218741\tvalid_0's binary_logloss: 0.556522\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.119363\tvalid_0's binary_logloss: 0.209088\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.244967\tvalid_0's binary_logloss: 0.680719\n",
            "[200]\tvalid_0's average_precision: 0.234619\tvalid_0's binary_logloss: 0.76336\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.112271\tvalid_0's binary_logloss: 0.201243\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.244967\tvalid_0's binary_logloss: 0.680719\n",
            "[200]\tvalid_0's average_precision: 0.234619\tvalid_0's binary_logloss: 0.76336\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.112271\tvalid_0's binary_logloss: 0.201243\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.242974\tvalid_0's binary_logloss: 0.677711\n",
            "[200]\tvalid_0's average_precision: 0.235509\tvalid_0's binary_logloss: 0.757978\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.12701\tvalid_0's binary_logloss: 0.201035\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.242974\tvalid_0's binary_logloss: 0.677711\n",
            "[200]\tvalid_0's average_precision: 0.235509\tvalid_0's binary_logloss: 0.757978\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.12701\tvalid_0's binary_logloss: 0.201035\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.235315\tvalid_0's binary_logloss: 0.747064\n",
            "[200]\tvalid_0's average_precision: 0.23084\tvalid_0's binary_logloss: 0.651728\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.112271\tvalid_0's binary_logloss: 0.210617\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.235315\tvalid_0's binary_logloss: 0.747064\n",
            "[200]\tvalid_0's average_precision: 0.23084\tvalid_0's binary_logloss: 0.651728\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.112271\tvalid_0's binary_logloss: 0.210617\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.235198\tvalid_0's binary_logloss: 0.743319\n",
            "[200]\tvalid_0's average_precision: 0.218827\tvalid_0's binary_logloss: 0.644214\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.12701\tvalid_0's binary_logloss: 0.210046\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.235198\tvalid_0's binary_logloss: 0.743319\n",
            "[200]\tvalid_0's average_precision: 0.218827\tvalid_0's binary_logloss: 0.644214\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.12701\tvalid_0's binary_logloss: 0.210046\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.238927\tvalid_0's binary_logloss: 1.0246\n",
            "[200]\tvalid_0's average_precision: 0.248096\tvalid_0's binary_logloss: 1.24482\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.101922\tvalid_0's binary_logloss: 0.203602\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.238927\tvalid_0's binary_logloss: 1.0246\n",
            "[200]\tvalid_0's average_precision: 0.248096\tvalid_0's binary_logloss: 1.24482\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.101922\tvalid_0's binary_logloss: 0.203602\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.209092\tvalid_0's binary_logloss: 1.02372\n",
            "[200]\tvalid_0's average_precision: 0.236441\tvalid_0's binary_logloss: 1.2442\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103064\tvalid_0's binary_logloss: 0.203711\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.209092\tvalid_0's binary_logloss: 1.02372\n",
            "[200]\tvalid_0's average_precision: 0.236441\tvalid_0's binary_logloss: 1.2442\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103064\tvalid_0's binary_logloss: 0.203711\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.247408\tvalid_0's binary_logloss: 1.24713\n",
            "[200]\tvalid_0's average_precision: 0.235908\tvalid_0's binary_logloss: 1.1343\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.101922\tvalid_0's binary_logloss: 0.218695\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.247408\tvalid_0's binary_logloss: 1.24713\n",
            "[200]\tvalid_0's average_precision: 0.235908\tvalid_0's binary_logloss: 1.1343\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.101922\tvalid_0's binary_logloss: 0.218695\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.247032\tvalid_0's binary_logloss: 1.24721\n",
            "[200]\tvalid_0's average_precision: 0.243292\tvalid_0's binary_logloss: 1.13151\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103064\tvalid_0's binary_logloss: 0.219006\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.247032\tvalid_0's binary_logloss: 1.24721\n",
            "[200]\tvalid_0's average_precision: 0.243292\tvalid_0's binary_logloss: 1.13151\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.103064\tvalid_0's binary_logloss: 0.219006\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.245801\tvalid_0's binary_logloss: 1.03309\n",
            "[200]\tvalid_0's average_precision: 0.244561\tvalid_0's binary_logloss: 1.26821\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.101968\tvalid_0's binary_logloss: 0.203761\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.245801\tvalid_0's binary_logloss: 1.03309\n",
            "[200]\tvalid_0's average_precision: 0.244561\tvalid_0's binary_logloss: 1.26821\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.101968\tvalid_0's binary_logloss: 0.203761\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.212001\tvalid_0's binary_logloss: 1.03336\n",
            "[200]\tvalid_0's average_precision: 0.234564\tvalid_0's binary_logloss: 1.26833\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.106589\tvalid_0's binary_logloss: 0.203696\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.212001\tvalid_0's binary_logloss: 1.03336\n",
            "[200]\tvalid_0's average_precision: 0.234564\tvalid_0's binary_logloss: 1.26833\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.106589\tvalid_0's binary_logloss: 0.203696\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241513\tvalid_0's binary_logloss: 1.2774\n",
            "[200]\tvalid_0's average_precision: 0.246539\tvalid_0's binary_logloss: 1.19294\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.101968\tvalid_0's binary_logloss: 0.219101\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241513\tvalid_0's binary_logloss: 1.2774\n",
            "[200]\tvalid_0's average_precision: 0.246539\tvalid_0's binary_logloss: 1.19294\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.101968\tvalid_0's binary_logloss: 0.219101\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.248946\tvalid_0's binary_logloss: 1.27118\n",
            "[200]\tvalid_0's average_precision: 0.246773\tvalid_0's binary_logloss: 1.18511\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.106589\tvalid_0's binary_logloss: 0.218943\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.248946\tvalid_0's binary_logloss: 1.27118\n",
            "[200]\tvalid_0's average_precision: 0.246773\tvalid_0's binary_logloss: 1.18511\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.106589\tvalid_0's binary_logloss: 0.218943\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.242067\tvalid_0's binary_logloss: 0.945854\n",
            "[200]\tvalid_0's average_precision: 0.243861\tvalid_0's binary_logloss: 1.1228\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.102582\tvalid_0's binary_logloss: 0.203095\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.242067\tvalid_0's binary_logloss: 0.945854\n",
            "[200]\tvalid_0's average_precision: 0.243861\tvalid_0's binary_logloss: 1.1228\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.102582\tvalid_0's binary_logloss: 0.203095\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.2181\tvalid_0's binary_logloss: 0.943349\n",
            "[200]\tvalid_0's average_precision: 0.242174\tvalid_0's binary_logloss: 1.12056\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105806\tvalid_0's binary_logloss: 0.203088\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.2181\tvalid_0's binary_logloss: 0.943349\n",
            "[200]\tvalid_0's average_precision: 0.242174\tvalid_0's binary_logloss: 1.12056\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105806\tvalid_0's binary_logloss: 0.203088\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.236099\tvalid_0's binary_logloss: 1.11246\n",
            "[200]\tvalid_0's average_precision: 0.227203\tvalid_0's binary_logloss: 0.950898\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.102582\tvalid_0's binary_logloss: 0.217329\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.236099\tvalid_0's binary_logloss: 1.11246\n",
            "[200]\tvalid_0's average_precision: 0.227203\tvalid_0's binary_logloss: 0.950898\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.102582\tvalid_0's binary_logloss: 0.217329\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.245323\tvalid_0's binary_logloss: 1.10117\n",
            "[200]\tvalid_0's average_precision: 0.233049\tvalid_0's binary_logloss: 0.936838\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105806\tvalid_0's binary_logloss: 0.217288\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.245323\tvalid_0's binary_logloss: 1.10117\n",
            "[200]\tvalid_0's average_precision: 0.233049\tvalid_0's binary_logloss: 0.936838\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105806\tvalid_0's binary_logloss: 0.217288\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.251458\tvalid_0's binary_logloss: 0.971386\n",
            "[200]\tvalid_0's average_precision: 0.241067\tvalid_0's binary_logloss: 1.1719\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105047\tvalid_0's binary_logloss: 0.203406\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.251458\tvalid_0's binary_logloss: 0.971386\n",
            "[200]\tvalid_0's average_precision: 0.241067\tvalid_0's binary_logloss: 1.1719\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105047\tvalid_0's binary_logloss: 0.203406\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.233465\tvalid_0's binary_logloss: 0.968236\n",
            "[200]\tvalid_0's average_precision: 0.247176\tvalid_0's binary_logloss: 1.1681\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.1066\tvalid_0's binary_logloss: 0.203157\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.233465\tvalid_0's binary_logloss: 0.968236\n",
            "[200]\tvalid_0's average_precision: 0.247176\tvalid_0's binary_logloss: 1.1681\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.1066\tvalid_0's binary_logloss: 0.203157\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241349\tvalid_0's binary_logloss: 1.17133\n",
            "[200]\tvalid_0's average_precision: 0.238387\tvalid_0's binary_logloss: 1.05478\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105047\tvalid_0's binary_logloss: 0.218054\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241349\tvalid_0's binary_logloss: 1.17133\n",
            "[200]\tvalid_0's average_precision: 0.238387\tvalid_0's binary_logloss: 1.05478\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.105047\tvalid_0's binary_logloss: 0.218054\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.249417\tvalid_0's binary_logloss: 1.16105\n",
            "[200]\tvalid_0's average_precision: 0.237169\tvalid_0's binary_logloss: 1.03948\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.1066\tvalid_0's binary_logloss: 0.217406\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.249417\tvalid_0's binary_logloss: 1.16105\n",
            "[200]\tvalid_0's average_precision: 0.237169\tvalid_0's binary_logloss: 1.03948\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.1066\tvalid_0's binary_logloss: 0.217406\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25368\tvalid_0's binary_logloss: 0.842057\n",
            "[200]\tvalid_0's average_precision: 0.243248\tvalid_0's binary_logloss: 0.964153\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.121811\tvalid_0's binary_logloss: 0.202441\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.25368\tvalid_0's binary_logloss: 0.842057\n",
            "[200]\tvalid_0's average_precision: 0.243248\tvalid_0's binary_logloss: 0.964153\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.121811\tvalid_0's binary_logloss: 0.202441\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.235195\tvalid_0's binary_logloss: 0.834441\n",
            "[200]\tvalid_0's average_precision: 0.239165\tvalid_0's binary_logloss: 0.957839\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.112188\tvalid_0's binary_logloss: 0.202129\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.235195\tvalid_0's binary_logloss: 0.834441\n",
            "[200]\tvalid_0's average_precision: 0.239165\tvalid_0's binary_logloss: 0.957839\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.112188\tvalid_0's binary_logloss: 0.202129\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.221024\tvalid_0's binary_logloss: 0.938531\n",
            "[200]\tvalid_0's average_precision: 0.215853\tvalid_0's binary_logloss: 0.744616\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.121811\tvalid_0's binary_logloss: 0.215527\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.221024\tvalid_0's binary_logloss: 0.938531\n",
            "[200]\tvalid_0's average_precision: 0.215853\tvalid_0's binary_logloss: 0.744616\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.121811\tvalid_0's binary_logloss: 0.215527\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.228593\tvalid_0's binary_logloss: 0.921872\n",
            "[200]\tvalid_0's average_precision: 0.217708\tvalid_0's binary_logloss: 0.726985\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.112188\tvalid_0's binary_logloss: 0.214647\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.228593\tvalid_0's binary_logloss: 0.921872\n",
            "[200]\tvalid_0's average_precision: 0.217708\tvalid_0's binary_logloss: 0.726985\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.112188\tvalid_0's binary_logloss: 0.214647\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[100]\tvalid_0's average_precision: 0.254845\tvalid_0's binary_logloss: 0.902973\n",
            "[200]\tvalid_0's average_precision: 0.240753\tvalid_0's binary_logloss: 1.06333\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.120216\tvalid_0's binary_logloss: 0.203104\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[100]\tvalid_0's average_precision: 0.254845\tvalid_0's binary_logloss: 0.902973\n",
            "[200]\tvalid_0's average_precision: 0.240753\tvalid_0's binary_logloss: 1.06333\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.120216\tvalid_0's binary_logloss: 0.203104\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.239082\tvalid_0's binary_logloss: 0.89476\n",
            "[200]\tvalid_0's average_precision: 0.242979\tvalid_0's binary_logloss: 1.05446\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.126121\tvalid_0's binary_logloss: 0.202684\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.239082\tvalid_0's binary_logloss: 0.89476\n",
            "[200]\tvalid_0's average_precision: 0.242979\tvalid_0's binary_logloss: 1.05446\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.126121\tvalid_0's binary_logloss: 0.202684\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.235459\tvalid_0's binary_logloss: 1.04835\n",
            "[200]\tvalid_0's average_precision: 0.224945\tvalid_0's binary_logloss: 0.898192\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.120216\tvalid_0's binary_logloss: 0.217151\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.235459\tvalid_0's binary_logloss: 1.04835\n",
            "[200]\tvalid_0's average_precision: 0.224945\tvalid_0's binary_logloss: 0.898192\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.120216\tvalid_0's binary_logloss: 0.217151\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241912\tvalid_0's binary_logloss: 1.03767\n",
            "[200]\tvalid_0's average_precision: 0.225396\tvalid_0's binary_logloss: 0.884579\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.126121\tvalid_0's binary_logloss: 0.215974\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 51485\n",
            "[LightGBM] [Info] Total Bins 1785\n",
            "[LightGBM] [Info] Number of data points in the train set: 55927, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079425 -> initscore=-2.450186\n",
            "[LightGBM] [Info] Start training from score -2.450186\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's average_precision: 0.241912\tvalid_0's binary_logloss: 1.03767\n",
            "[200]\tvalid_0's average_precision: 0.225396\tvalid_0's binary_logloss: 0.884579\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's average_precision: 0.126121\tvalid_0's binary_logloss: 0.215974\n",
            "[0]\ttrain-aucpr:0.12672\tvalid-aucpr:0.10796\n",
            "[100]\ttrain-aucpr:0.18377\tvalid-aucpr:0.26071\n",
            "[200]\ttrain-aucpr:0.19568\tvalid-aucpr:0.25639\n",
            "[291]\ttrain-aucpr:0.20621\tvalid-aucpr:0.25812\n",
            "[0]\ttrain-aucpr:0.12926\tvalid-aucpr:0.14462\n",
            "[100]\ttrain-aucpr:0.18233\tvalid-aucpr:0.25966\n",
            "[200]\ttrain-aucpr:0.19459\tvalid-aucpr:0.25809\n",
            "[260]\ttrain-aucpr:0.20136\tvalid-aucpr:0.25864\n",
            "[0]\ttrain-aucpr:0.13783\tvalid-aucpr:0.13947\n",
            "[100]\ttrain-aucpr:0.18104\tvalid-aucpr:0.24306\n",
            "[200]\ttrain-aucpr:0.19616\tvalid-aucpr:0.25422\n",
            "[300]\ttrain-aucpr:0.20985\tvalid-aucpr:0.25908\n",
            "[400]\ttrain-aucpr:0.22443\tvalid-aucpr:0.26044\n",
            "[500]\ttrain-aucpr:0.23967\tvalid-aucpr:0.25979\n",
            "[600]\ttrain-aucpr:0.25266\tvalid-aucpr:0.25587\n",
            "[632]\ttrain-aucpr:0.25718\tvalid-aucpr:0.25629\n",
            "[0]\ttrain-aucpr:0.14461\tvalid-aucpr:0.16423\n",
            "[100]\ttrain-aucpr:0.17901\tvalid-aucpr:0.23623\n",
            "[200]\ttrain-aucpr:0.19564\tvalid-aucpr:0.24766\n",
            "[300]\ttrain-aucpr:0.20859\tvalid-aucpr:0.24835\n",
            "[400]\ttrain-aucpr:0.22257\tvalid-aucpr:0.24917\n",
            "[446]\ttrain-aucpr:0.22921\tvalid-aucpr:0.24774\n",
            "[0]\ttrain-aucpr:0.12672\tvalid-aucpr:0.10796\n",
            "[100]\ttrain-aucpr:0.19802\tvalid-aucpr:0.25385\n",
            "[200]\ttrain-aucpr:0.22660\tvalid-aucpr:0.25235\n",
            "[300]\ttrain-aucpr:0.25513\tvalid-aucpr:0.24738\n",
            "[345]\ttrain-aucpr:0.26736\tvalid-aucpr:0.24369\n",
            "[0]\ttrain-aucpr:0.12926\tvalid-aucpr:0.14462\n",
            "[100]\ttrain-aucpr:0.20052\tvalid-aucpr:0.25254\n",
            "[200]\ttrain-aucpr:0.23024\tvalid-aucpr:0.25411\n",
            "[300]\ttrain-aucpr:0.25820\tvalid-aucpr:0.24219\n",
            "[340]\ttrain-aucpr:0.26969\tvalid-aucpr:0.23891\n",
            "[0]\ttrain-aucpr:0.13783\tvalid-aucpr:0.13947\n",
            "[100]\ttrain-aucpr:0.20362\tvalid-aucpr:0.25588\n",
            "[200]\ttrain-aucpr:0.23657\tvalid-aucpr:0.24261\n",
            "[296]\ttrain-aucpr:0.26695\tvalid-aucpr:0.23871\n",
            "[0]\ttrain-aucpr:0.14461\tvalid-aucpr:0.16423\n",
            "[100]\ttrain-aucpr:0.20127\tvalid-aucpr:0.24923\n",
            "[200]\ttrain-aucpr:0.23673\tvalid-aucpr:0.25086\n",
            "[300]\ttrain-aucpr:0.27078\tvalid-aucpr:0.24167\n",
            "[334]\ttrain-aucpr:0.28244\tvalid-aucpr:0.24071\n",
            "[0]\ttrain-aucpr:0.12672\tvalid-aucpr:0.10796\n",
            "[100]\ttrain-aucpr:0.18336\tvalid-aucpr:0.26066\n",
            "[200]\ttrain-aucpr:0.19491\tvalid-aucpr:0.25785\n",
            "[300]\ttrain-aucpr:0.20596\tvalid-aucpr:0.25929\n",
            "[311]\ttrain-aucpr:0.20715\tvalid-aucpr:0.25929\n",
            "[0]\ttrain-aucpr:0.12926\tvalid-aucpr:0.14462\n",
            "[100]\ttrain-aucpr:0.18218\tvalid-aucpr:0.26001\n",
            "[200]\ttrain-aucpr:0.19423\tvalid-aucpr:0.25859\n",
            "[261]\ttrain-aucpr:0.20114\tvalid-aucpr:0.25955\n",
            "[0]\ttrain-aucpr:0.13783\tvalid-aucpr:0.13947\n",
            "[100]\ttrain-aucpr:0.18052\tvalid-aucpr:0.24172\n",
            "[200]\ttrain-aucpr:0.19450\tvalid-aucpr:0.25319\n",
            "[300]\ttrain-aucpr:0.20781\tvalid-aucpr:0.25949\n",
            "[400]\ttrain-aucpr:0.22088\tvalid-aucpr:0.26028\n",
            "[500]\ttrain-aucpr:0.23485\tvalid-aucpr:0.25958\n",
            "[600]\ttrain-aucpr:0.24817\tvalid-aucpr:0.25531\n",
            "[653]\ttrain-aucpr:0.25468\tvalid-aucpr:0.25341\n",
            "[0]\ttrain-aucpr:0.14461\tvalid-aucpr:0.16423\n",
            "[100]\ttrain-aucpr:0.17902\tvalid-aucpr:0.23546\n",
            "[200]\ttrain-aucpr:0.19383\tvalid-aucpr:0.24811\n",
            "[300]\ttrain-aucpr:0.20688\tvalid-aucpr:0.24974\n",
            "[400]\ttrain-aucpr:0.22023\tvalid-aucpr:0.25203\n",
            "[500]\ttrain-aucpr:0.23370\tvalid-aucpr:0.25252\n",
            "[600]\ttrain-aucpr:0.24797\tvalid-aucpr:0.24698\n",
            "[634]\ttrain-aucpr:0.25251\tvalid-aucpr:0.24422\n",
            "[0]\ttrain-aucpr:0.12672\tvalid-aucpr:0.10796\n",
            "[100]\ttrain-aucpr:0.19725\tvalid-aucpr:0.25707\n",
            "[200]\ttrain-aucpr:0.22585\tvalid-aucpr:0.25291\n",
            "[297]\ttrain-aucpr:0.25114\tvalid-aucpr:0.25125\n",
            "[0]\ttrain-aucpr:0.12926\tvalid-aucpr:0.14462\n",
            "[100]\ttrain-aucpr:0.19958\tvalid-aucpr:0.25306\n",
            "[200]\ttrain-aucpr:0.22967\tvalid-aucpr:0.24884\n",
            "[300]\ttrain-aucpr:0.25672\tvalid-aucpr:0.24094\n",
            "[313]\ttrain-aucpr:0.26099\tvalid-aucpr:0.23919\n",
            "[0]\ttrain-aucpr:0.13783\tvalid-aucpr:0.13947\n",
            "[100]\ttrain-aucpr:0.20306\tvalid-aucpr:0.25394\n",
            "[200]\ttrain-aucpr:0.23325\tvalid-aucpr:0.25004\n",
            "[286]\ttrain-aucpr:0.25912\tvalid-aucpr:0.24718\n",
            "[0]\ttrain-aucpr:0.14461\tvalid-aucpr:0.16423\n",
            "[100]\ttrain-aucpr:0.19976\tvalid-aucpr:0.25267\n",
            "[200]\ttrain-aucpr:0.23254\tvalid-aucpr:0.25170\n",
            "[300]\ttrain-aucpr:0.26320\tvalid-aucpr:0.24152\n",
            "[332]\ttrain-aucpr:0.27288\tvalid-aucpr:0.23920\n",
            "[0]\ttrain-aucpr:0.16521\tvalid-aucpr:0.14795\n",
            "[100]\ttrain-aucpr:0.31223\tvalid-aucpr:0.25560\n",
            "[200]\ttrain-aucpr:0.36086\tvalid-aucpr:0.24849\n",
            "[290]\ttrain-aucpr:0.40988\tvalid-aucpr:0.23860\n",
            "[0]\ttrain-aucpr:0.17745\tvalid-aucpr:0.15452\n",
            "[100]\ttrain-aucpr:0.32071\tvalid-aucpr:0.25287\n",
            "[200]\ttrain-aucpr:0.37427\tvalid-aucpr:0.24417\n",
            "[292]\ttrain-aucpr:0.42268\tvalid-aucpr:0.23697\n",
            "[0]\ttrain-aucpr:0.18341\tvalid-aucpr:0.14201\n",
            "[100]\ttrain-aucpr:0.30763\tvalid-aucpr:0.24298\n",
            "[200]\ttrain-aucpr:0.36890\tvalid-aucpr:0.24322\n",
            "[300]\ttrain-aucpr:0.43077\tvalid-aucpr:0.24246\n",
            "[340]\ttrain-aucpr:0.45846\tvalid-aucpr:0.24155\n",
            "[0]\ttrain-aucpr:0.19646\tvalid-aucpr:0.15960\n",
            "[100]\ttrain-aucpr:0.31021\tvalid-aucpr:0.24032\n",
            "[200]\ttrain-aucpr:0.37046\tvalid-aucpr:0.24557\n",
            "[300]\ttrain-aucpr:0.43486\tvalid-aucpr:0.24423\n",
            "[400]\ttrain-aucpr:0.50069\tvalid-aucpr:0.23937\n",
            "[425]\ttrain-aucpr:0.51746\tvalid-aucpr:0.23942\n",
            "[0]\ttrain-aucpr:0.16521\tvalid-aucpr:0.14795\n",
            "[100]\ttrain-aucpr:0.37518\tvalid-aucpr:0.23908\n",
            "[200]\ttrain-aucpr:0.51255\tvalid-aucpr:0.22485\n",
            "[234]\ttrain-aucpr:0.55880\tvalid-aucpr:0.21583\n",
            "[0]\ttrain-aucpr:0.17745\tvalid-aucpr:0.15452\n",
            "[100]\ttrain-aucpr:0.38696\tvalid-aucpr:0.23951\n",
            "[200]\ttrain-aucpr:0.52714\tvalid-aucpr:0.23173\n",
            "[238]\ttrain-aucpr:0.57594\tvalid-aucpr:0.22428\n",
            "[0]\ttrain-aucpr:0.18341\tvalid-aucpr:0.14201\n",
            "[100]\ttrain-aucpr:0.38860\tvalid-aucpr:0.24049\n",
            "[200]\ttrain-aucpr:0.53835\tvalid-aucpr:0.22539\n",
            "[245]\ttrain-aucpr:0.59912\tvalid-aucpr:0.21634\n",
            "[0]\ttrain-aucpr:0.19646\tvalid-aucpr:0.15960\n",
            "[100]\ttrain-aucpr:0.40383\tvalid-aucpr:0.23629\n",
            "[200]\ttrain-aucpr:0.55923\tvalid-aucpr:0.22039\n",
            "[257]\ttrain-aucpr:0.62971\tvalid-aucpr:0.21291\n",
            "[0]\ttrain-aucpr:0.16602\tvalid-aucpr:0.15009\n",
            "[100]\ttrain-aucpr:0.30420\tvalid-aucpr:0.25461\n",
            "[200]\ttrain-aucpr:0.34537\tvalid-aucpr:0.24804\n",
            "[300]\ttrain-aucpr:0.38895\tvalid-aucpr:0.23857\n",
            "[310]\ttrain-aucpr:0.39488\tvalid-aucpr:0.23728\n",
            "[0]\ttrain-aucpr:0.17660\tvalid-aucpr:0.16242\n",
            "[100]\ttrain-aucpr:0.31198\tvalid-aucpr:0.25566\n",
            "[200]\ttrain-aucpr:0.35703\tvalid-aucpr:0.24334\n",
            "[238]\ttrain-aucpr:0.37513\tvalid-aucpr:0.24172\n",
            "[0]\ttrain-aucpr:0.18484\tvalid-aucpr:0.15264\n",
            "[100]\ttrain-aucpr:0.29747\tvalid-aucpr:0.24508\n",
            "[200]\ttrain-aucpr:0.34803\tvalid-aucpr:0.24438\n",
            "[300]\ttrain-aucpr:0.40241\tvalid-aucpr:0.24109\n",
            "[323]\ttrain-aucpr:0.41598\tvalid-aucpr:0.24077\n",
            "[0]\ttrain-aucpr:0.19693\tvalid-aucpr:0.16516\n",
            "[100]\ttrain-aucpr:0.30240\tvalid-aucpr:0.24110\n",
            "[200]\ttrain-aucpr:0.35446\tvalid-aucpr:0.24506\n",
            "[300]\ttrain-aucpr:0.41038\tvalid-aucpr:0.24205\n",
            "[400]\ttrain-aucpr:0.46733\tvalid-aucpr:0.24031\n",
            "[435]\ttrain-aucpr:0.48704\tvalid-aucpr:0.23953\n",
            "[0]\ttrain-aucpr:0.16602\tvalid-aucpr:0.15009\n",
            "[100]\ttrain-aucpr:0.35593\tvalid-aucpr:0.23384\n",
            "[200]\ttrain-aucpr:0.46806\tvalid-aucpr:0.22233\n",
            "[233]\ttrain-aucpr:0.50016\tvalid-aucpr:0.22254\n",
            "[0]\ttrain-aucpr:0.17660\tvalid-aucpr:0.16242\n",
            "[100]\ttrain-aucpr:0.37486\tvalid-aucpr:0.24275\n",
            "[200]\ttrain-aucpr:0.49050\tvalid-aucpr:0.23377\n",
            "[216]\ttrain-aucpr:0.50884\tvalid-aucpr:0.23386\n",
            "[0]\ttrain-aucpr:0.18484\tvalid-aucpr:0.15264\n",
            "[100]\ttrain-aucpr:0.36839\tvalid-aucpr:0.24298\n",
            "[200]\ttrain-aucpr:0.49644\tvalid-aucpr:0.23284\n",
            "[264]\ttrain-aucpr:0.56992\tvalid-aucpr:0.22549\n",
            "[0]\ttrain-aucpr:0.19693\tvalid-aucpr:0.16516\n",
            "[100]\ttrain-aucpr:0.37874\tvalid-aucpr:0.24175\n",
            "[200]\ttrain-aucpr:0.50870\tvalid-aucpr:0.21912\n",
            "[255]\ttrain-aucpr:0.57246\tvalid-aucpr:0.21496\n",
            "[0]\ttrain-aucpr:0.12638\tvalid-aucpr:0.12680\n",
            "[100]\ttrain-aucpr:0.17999\tvalid-aucpr:0.26290\n",
            "[200]\ttrain-aucpr:0.19143\tvalid-aucpr:0.25905\n",
            "[300]\ttrain-aucpr:0.20256\tvalid-aucpr:0.25955\n",
            "[400]\ttrain-aucpr:0.21324\tvalid-aucpr:0.26212\n",
            "[451]\ttrain-aucpr:0.21844\tvalid-aucpr:0.26124\n",
            "[0]\ttrain-aucpr:0.12683\tvalid-aucpr:0.13781\n",
            "[100]\ttrain-aucpr:0.17891\tvalid-aucpr:0.25872\n",
            "[200]\ttrain-aucpr:0.19136\tvalid-aucpr:0.25774\n",
            "[300]\ttrain-aucpr:0.20148\tvalid-aucpr:0.25733\n",
            "[320]\ttrain-aucpr:0.20366\tvalid-aucpr:0.25741\n",
            "[0]\ttrain-aucpr:0.13568\tvalid-aucpr:0.13452\n",
            "[100]\ttrain-aucpr:0.17697\tvalid-aucpr:0.24086\n",
            "[200]\ttrain-aucpr:0.19148\tvalid-aucpr:0.25611\n",
            "[300]\ttrain-aucpr:0.20369\tvalid-aucpr:0.26041\n",
            "[400]\ttrain-aucpr:0.21751\tvalid-aucpr:0.26058\n",
            "[464]\ttrain-aucpr:0.22528\tvalid-aucpr:0.26141\n",
            "[0]\ttrain-aucpr:0.14196\tvalid-aucpr:0.15850\n",
            "[100]\ttrain-aucpr:0.17462\tvalid-aucpr:0.23502\n",
            "[200]\ttrain-aucpr:0.19025\tvalid-aucpr:0.25251\n",
            "[300]\ttrain-aucpr:0.20369\tvalid-aucpr:0.25105\n",
            "[400]\ttrain-aucpr:0.21626\tvalid-aucpr:0.25199\n",
            "[435]\ttrain-aucpr:0.22161\tvalid-aucpr:0.25173\n",
            "[0]\ttrain-aucpr:0.12638\tvalid-aucpr:0.12680\n",
            "[100]\ttrain-aucpr:0.19334\tvalid-aucpr:0.25529\n",
            "[200]\ttrain-aucpr:0.22109\tvalid-aucpr:0.24916\n",
            "[297]\ttrain-aucpr:0.24369\tvalid-aucpr:0.24934\n",
            "[0]\ttrain-aucpr:0.12683\tvalid-aucpr:0.13781\n",
            "[100]\ttrain-aucpr:0.19602\tvalid-aucpr:0.24620\n",
            "[200]\ttrain-aucpr:0.22465\tvalid-aucpr:0.24798\n",
            "[300]\ttrain-aucpr:0.25263\tvalid-aucpr:0.23437\n",
            "[349]\ttrain-aucpr:0.26584\tvalid-aucpr:0.23302\n",
            "[0]\ttrain-aucpr:0.13568\tvalid-aucpr:0.13452\n",
            "[100]\ttrain-aucpr:0.19780\tvalid-aucpr:0.25675\n",
            "[200]\ttrain-aucpr:0.22760\tvalid-aucpr:0.25669\n",
            "[300]\ttrain-aucpr:0.25447\tvalid-aucpr:0.25271\n",
            "[331]\ttrain-aucpr:0.26554\tvalid-aucpr:0.24278\n",
            "[0]\ttrain-aucpr:0.14196\tvalid-aucpr:0.15850\n",
            "[100]\ttrain-aucpr:0.19530\tvalid-aucpr:0.24831\n",
            "[200]\ttrain-aucpr:0.23006\tvalid-aucpr:0.24339\n",
            "[300]\ttrain-aucpr:0.25935\tvalid-aucpr:0.23642\n",
            "[315]\ttrain-aucpr:0.26435\tvalid-aucpr:0.23711\n",
            "[0]\ttrain-aucpr:0.12638\tvalid-aucpr:0.12680\n",
            "[100]\ttrain-aucpr:0.18005\tvalid-aucpr:0.26300\n",
            "[200]\ttrain-aucpr:0.19059\tvalid-aucpr:0.25839\n",
            "[300]\ttrain-aucpr:0.20140\tvalid-aucpr:0.25889\n",
            "[0]\ttrain-aucpr:0.12683\tvalid-aucpr:0.13781\n",
            "[100]\ttrain-aucpr:0.17852\tvalid-aucpr:0.25890\n",
            "[200]\ttrain-aucpr:0.19068\tvalid-aucpr:0.25796\n",
            "[300]\ttrain-aucpr:0.20132\tvalid-aucpr:0.25796\n",
            "[320]\ttrain-aucpr:0.20334\tvalid-aucpr:0.25753\n",
            "[0]\ttrain-aucpr:0.13568\tvalid-aucpr:0.13452\n",
            "[100]\ttrain-aucpr:0.17679\tvalid-aucpr:0.24007\n",
            "[200]\ttrain-aucpr:0.19029\tvalid-aucpr:0.25600\n",
            "[300]\ttrain-aucpr:0.20330\tvalid-aucpr:0.25865\n",
            "[400]\ttrain-aucpr:0.21495\tvalid-aucpr:0.26039\n",
            "[500]\ttrain-aucpr:0.22746\tvalid-aucpr:0.26155\n",
            "[600]\ttrain-aucpr:0.24035\tvalid-aucpr:0.25628\n",
            "[658]\ttrain-aucpr:0.24690\tvalid-aucpr:0.25381\n",
            "[0]\ttrain-aucpr:0.14196\tvalid-aucpr:0.15850\n",
            "[100]\ttrain-aucpr:0.17422\tvalid-aucpr:0.23753\n",
            "[200]\ttrain-aucpr:0.18902\tvalid-aucpr:0.25078\n",
            "[300]\ttrain-aucpr:0.20206\tvalid-aucpr:0.25064\n",
            "[400]\ttrain-aucpr:0.21480\tvalid-aucpr:0.25358\n",
            "[500]\ttrain-aucpr:0.22827\tvalid-aucpr:0.25145\n",
            "[600]\ttrain-aucpr:0.24067\tvalid-aucpr:0.24755\n",
            "[632]\ttrain-aucpr:0.24509\tvalid-aucpr:0.24596\n",
            "[0]\ttrain-aucpr:0.12638\tvalid-aucpr:0.12680\n",
            "[100]\ttrain-aucpr:0.19404\tvalid-aucpr:0.25489\n",
            "[200]\ttrain-aucpr:0.21942\tvalid-aucpr:0.24470\n",
            "[296]\ttrain-aucpr:0.24110\tvalid-aucpr:0.24309\n",
            "[0]\ttrain-aucpr:0.12683\tvalid-aucpr:0.13781\n",
            "[100]\ttrain-aucpr:0.19801\tvalid-aucpr:0.24473\n",
            "[200]\ttrain-aucpr:0.22522\tvalid-aucpr:0.24356\n",
            "[289]\ttrain-aucpr:0.24864\tvalid-aucpr:0.23341\n",
            "[0]\ttrain-aucpr:0.13568\tvalid-aucpr:0.13452\n",
            "[100]\ttrain-aucpr:0.19640\tvalid-aucpr:0.25166\n",
            "[200]\ttrain-aucpr:0.22496\tvalid-aucpr:0.24810\n",
            "[300]\ttrain-aucpr:0.25068\tvalid-aucpr:0.24206\n",
            "[307]\ttrain-aucpr:0.25220\tvalid-aucpr:0.24129\n",
            "[0]\ttrain-aucpr:0.14196\tvalid-aucpr:0.15850\n",
            "[100]\ttrain-aucpr:0.19396\tvalid-aucpr:0.25189\n",
            "[200]\ttrain-aucpr:0.22742\tvalid-aucpr:0.24979\n",
            "[300]\ttrain-aucpr:0.25546\tvalid-aucpr:0.24223\n",
            "[333]\ttrain-aucpr:0.26606\tvalid-aucpr:0.23784\n",
            "[0]\ttrain-aucpr:0.15884\tvalid-aucpr:0.14807\n",
            "[100]\ttrain-aucpr:0.29708\tvalid-aucpr:0.24426\n",
            "[200]\ttrain-aucpr:0.34441\tvalid-aucpr:0.23918\n",
            "[286]\ttrain-aucpr:0.39154\tvalid-aucpr:0.23644\n",
            "[0]\ttrain-aucpr:0.17043\tvalid-aucpr:0.14824\n",
            "[100]\ttrain-aucpr:0.30644\tvalid-aucpr:0.24121\n",
            "[200]\ttrain-aucpr:0.35840\tvalid-aucpr:0.23458\n",
            "[300]\ttrain-aucpr:0.41103\tvalid-aucpr:0.22524\n",
            "[306]\ttrain-aucpr:0.41520\tvalid-aucpr:0.22410\n",
            "[0]\ttrain-aucpr:0.17771\tvalid-aucpr:0.15568\n",
            "[100]\ttrain-aucpr:0.29013\tvalid-aucpr:0.23175\n",
            "[200]\ttrain-aucpr:0.34626\tvalid-aucpr:0.23318\n",
            "[300]\ttrain-aucpr:0.40514\tvalid-aucpr:0.23616\n",
            "[400]\ttrain-aucpr:0.46982\tvalid-aucpr:0.23030\n",
            "[473]\ttrain-aucpr:0.51101\tvalid-aucpr:0.22874\n",
            "[0]\ttrain-aucpr:0.18774\tvalid-aucpr:0.15196\n",
            "[100]\ttrain-aucpr:0.29354\tvalid-aucpr:0.22994\n",
            "[200]\ttrain-aucpr:0.35081\tvalid-aucpr:0.23852\n",
            "[300]\ttrain-aucpr:0.41764\tvalid-aucpr:0.23552\n",
            "[400]\ttrain-aucpr:0.48152\tvalid-aucpr:0.23327\n",
            "[427]\ttrain-aucpr:0.49875\tvalid-aucpr:0.23458\n",
            "[0]\ttrain-aucpr:0.15884\tvalid-aucpr:0.14807\n",
            "[100]\ttrain-aucpr:0.36188\tvalid-aucpr:0.23292\n",
            "[200]\ttrain-aucpr:0.49234\tvalid-aucpr:0.22115\n",
            "[244]\ttrain-aucpr:0.54544\tvalid-aucpr:0.21238\n",
            "[0]\ttrain-aucpr:0.17043\tvalid-aucpr:0.14824\n",
            "[100]\ttrain-aucpr:0.37456\tvalid-aucpr:0.23827\n",
            "[200]\ttrain-aucpr:0.51627\tvalid-aucpr:0.21790\n",
            "[246]\ttrain-aucpr:0.58033\tvalid-aucpr:0.21048\n",
            "[0]\ttrain-aucpr:0.17771\tvalid-aucpr:0.15568\n",
            "[100]\ttrain-aucpr:0.36707\tvalid-aucpr:0.22667\n",
            "[200]\ttrain-aucpr:0.51103\tvalid-aucpr:0.21959\n",
            "[234]\ttrain-aucpr:0.55519\tvalid-aucpr:0.21713\n",
            "[0]\ttrain-aucpr:0.18774\tvalid-aucpr:0.15196\n",
            "[100]\ttrain-aucpr:0.37392\tvalid-aucpr:0.23767\n",
            "[200]\ttrain-aucpr:0.52333\tvalid-aucpr:0.22763\n",
            "[252]\ttrain-aucpr:0.58870\tvalid-aucpr:0.21966\n",
            "[0]\ttrain-aucpr:0.15953\tvalid-aucpr:0.15034\n",
            "[100]\ttrain-aucpr:0.29016\tvalid-aucpr:0.24774\n",
            "[200]\ttrain-aucpr:0.33368\tvalid-aucpr:0.24174\n",
            "[256]\ttrain-aucpr:0.36251\tvalid-aucpr:0.23931\n",
            "[0]\ttrain-aucpr:0.17171\tvalid-aucpr:0.14912\n",
            "[100]\ttrain-aucpr:0.30197\tvalid-aucpr:0.24682\n",
            "[200]\ttrain-aucpr:0.34856\tvalid-aucpr:0.23912\n",
            "[290]\ttrain-aucpr:0.38990\tvalid-aucpr:0.23117\n",
            "[0]\ttrain-aucpr:0.17959\tvalid-aucpr:0.15975\n",
            "[100]\ttrain-aucpr:0.28693\tvalid-aucpr:0.23527\n",
            "[200]\ttrain-aucpr:0.33833\tvalid-aucpr:0.23612\n",
            "[300]\ttrain-aucpr:0.39069\tvalid-aucpr:0.23860\n",
            "[400]\ttrain-aucpr:0.44828\tvalid-aucpr:0.23193\n",
            "[482]\ttrain-aucpr:0.49109\tvalid-aucpr:0.23005\n",
            "[0]\ttrain-aucpr:0.19071\tvalid-aucpr:0.15412\n",
            "[100]\ttrain-aucpr:0.28850\tvalid-aucpr:0.23568\n",
            "[200]\ttrain-aucpr:0.34110\tvalid-aucpr:0.24352\n",
            "[300]\ttrain-aucpr:0.39900\tvalid-aucpr:0.24129\n",
            "[400]\ttrain-aucpr:0.45577\tvalid-aucpr:0.23754\n",
            "[417]\ttrain-aucpr:0.46884\tvalid-aucpr:0.23711\n",
            "[0]\ttrain-aucpr:0.15953\tvalid-aucpr:0.15034\n",
            "[100]\ttrain-aucpr:0.34618\tvalid-aucpr:0.23478\n",
            "[200]\ttrain-aucpr:0.46544\tvalid-aucpr:0.21368\n",
            "[234]\ttrain-aucpr:0.50251\tvalid-aucpr:0.20791\n",
            "[0]\ttrain-aucpr:0.17171\tvalid-aucpr:0.14912\n",
            "[100]\ttrain-aucpr:0.36559\tvalid-aucpr:0.23825\n",
            "[200]\ttrain-aucpr:0.48875\tvalid-aucpr:0.22249\n",
            "[234]\ttrain-aucpr:0.53202\tvalid-aucpr:0.21971\n",
            "[0]\ttrain-aucpr:0.17959\tvalid-aucpr:0.15975\n",
            "[100]\ttrain-aucpr:0.35171\tvalid-aucpr:0.23766\n",
            "[200]\ttrain-aucpr:0.47970\tvalid-aucpr:0.22043\n",
            "[249]\ttrain-aucpr:0.53526\tvalid-aucpr:0.21533\n",
            "[0]\ttrain-aucpr:0.19071\tvalid-aucpr:0.15412\n",
            "[100]\ttrain-aucpr:0.36914\tvalid-aucpr:0.24304\n",
            "[200]\ttrain-aucpr:0.50707\tvalid-aucpr:0.23659\n",
            "[270]\ttrain-aucpr:0.58998\tvalid-aucpr:0.22678\n",
            "[0]\ttrain-aucpr:0.12025\tvalid-aucpr:0.12109\n",
            "[100]\ttrain-aucpr:0.17725\tvalid-aucpr:0.26119\n",
            "[200]\ttrain-aucpr:0.18983\tvalid-aucpr:0.25541\n",
            "[300]\ttrain-aucpr:0.20070\tvalid-aucpr:0.25793\n",
            "[312]\ttrain-aucpr:0.20174\tvalid-aucpr:0.25779\n",
            "[0]\ttrain-aucpr:0.12413\tvalid-aucpr:0.13568\n",
            "[100]\ttrain-aucpr:0.17599\tvalid-aucpr:0.25494\n",
            "[200]\ttrain-aucpr:0.18914\tvalid-aucpr:0.25751\n",
            "[300]\ttrain-aucpr:0.20161\tvalid-aucpr:0.25666\n",
            "[400]\ttrain-aucpr:0.21232\tvalid-aucpr:0.25687\n",
            "[434]\ttrain-aucpr:0.21627\tvalid-aucpr:0.25446\n",
            "[0]\ttrain-aucpr:0.13137\tvalid-aucpr:0.13210\n",
            "[100]\ttrain-aucpr:0.17182\tvalid-aucpr:0.23498\n",
            "[200]\ttrain-aucpr:0.18963\tvalid-aucpr:0.25390\n",
            "[300]\ttrain-aucpr:0.20254\tvalid-aucpr:0.25488\n",
            "[400]\ttrain-aucpr:0.21559\tvalid-aucpr:0.25379\n",
            "[463]\ttrain-aucpr:0.22236\tvalid-aucpr:0.25465\n",
            "[0]\ttrain-aucpr:0.13823\tvalid-aucpr:0.15328\n",
            "[100]\ttrain-aucpr:0.17022\tvalid-aucpr:0.23200\n",
            "[200]\ttrain-aucpr:0.18602\tvalid-aucpr:0.25147\n",
            "[300]\ttrain-aucpr:0.20003\tvalid-aucpr:0.25162\n",
            "[400]\ttrain-aucpr:0.21189\tvalid-aucpr:0.25425\n",
            "[500]\ttrain-aucpr:0.22494\tvalid-aucpr:0.25031\n",
            "[600]\ttrain-aucpr:0.23750\tvalid-aucpr:0.24518\n",
            "[621]\ttrain-aucpr:0.23996\tvalid-aucpr:0.24315\n",
            "[0]\ttrain-aucpr:0.12025\tvalid-aucpr:0.12109\n",
            "[100]\ttrain-aucpr:0.19165\tvalid-aucpr:0.25498\n",
            "[200]\ttrain-aucpr:0.21449\tvalid-aucpr:0.24771\n",
            "[296]\ttrain-aucpr:0.23676\tvalid-aucpr:0.24883\n",
            "[0]\ttrain-aucpr:0.12413\tvalid-aucpr:0.13568\n",
            "[100]\ttrain-aucpr:0.19117\tvalid-aucpr:0.25276\n",
            "[200]\ttrain-aucpr:0.22000\tvalid-aucpr:0.25132\n",
            "[289]\ttrain-aucpr:0.24259\tvalid-aucpr:0.23951\n",
            "[0]\ttrain-aucpr:0.13137\tvalid-aucpr:0.13210\n",
            "[100]\ttrain-aucpr:0.19482\tvalid-aucpr:0.25321\n",
            "[200]\ttrain-aucpr:0.22332\tvalid-aucpr:0.24677\n",
            "[300]\ttrain-aucpr:0.25002\tvalid-aucpr:0.24391\n",
            "[304]\ttrain-aucpr:0.25072\tvalid-aucpr:0.24328\n",
            "[0]\ttrain-aucpr:0.13823\tvalid-aucpr:0.15328\n",
            "[100]\ttrain-aucpr:0.19522\tvalid-aucpr:0.24795\n",
            "[200]\ttrain-aucpr:0.22526\tvalid-aucpr:0.23919\n",
            "[300]\ttrain-aucpr:0.25377\tvalid-aucpr:0.23384\n",
            "[317]\ttrain-aucpr:0.25924\tvalid-aucpr:0.23410\n",
            "[0]\ttrain-aucpr:0.12024\tvalid-aucpr:0.12171\n",
            "[100]\ttrain-aucpr:0.17748\tvalid-aucpr:0.26147\n",
            "[200]\ttrain-aucpr:0.18904\tvalid-aucpr:0.25652\n",
            "[300]\ttrain-aucpr:0.19876\tvalid-aucpr:0.26107\n",
            "[400]\ttrain-aucpr:0.20892\tvalid-aucpr:0.26397\n",
            "[500]\ttrain-aucpr:0.21807\tvalid-aucpr:0.26065\n",
            "[600]\ttrain-aucpr:0.22806\tvalid-aucpr:0.25738\n",
            "[608]\ttrain-aucpr:0.22897\tvalid-aucpr:0.25787\n",
            "[0]\ttrain-aucpr:0.12413\tvalid-aucpr:0.13568\n",
            "[100]\ttrain-aucpr:0.17579\tvalid-aucpr:0.25513\n",
            "[200]\ttrain-aucpr:0.18846\tvalid-aucpr:0.25733\n",
            "[300]\ttrain-aucpr:0.19941\tvalid-aucpr:0.25815\n",
            "[400]\ttrain-aucpr:0.20945\tvalid-aucpr:0.25502\n",
            "[431]\ttrain-aucpr:0.21258\tvalid-aucpr:0.25468\n",
            "[0]\ttrain-aucpr:0.13132\tvalid-aucpr:0.13274\n",
            "[100]\ttrain-aucpr:0.17249\tvalid-aucpr:0.23640\n",
            "[200]\ttrain-aucpr:0.18861\tvalid-aucpr:0.25179\n",
            "[300]\ttrain-aucpr:0.20096\tvalid-aucpr:0.25608\n",
            "[400]\ttrain-aucpr:0.21243\tvalid-aucpr:0.25517\n",
            "[464]\ttrain-aucpr:0.21886\tvalid-aucpr:0.25574\n",
            "[0]\ttrain-aucpr:0.13823\tvalid-aucpr:0.15328\n",
            "[100]\ttrain-aucpr:0.17038\tvalid-aucpr:0.23327\n",
            "[200]\ttrain-aucpr:0.18598\tvalid-aucpr:0.25400\n",
            "[300]\ttrain-aucpr:0.19875\tvalid-aucpr:0.25134\n",
            "[400]\ttrain-aucpr:0.20949\tvalid-aucpr:0.25637\n",
            "[500]\ttrain-aucpr:0.22253\tvalid-aucpr:0.25307\n",
            "[600]\ttrain-aucpr:0.23444\tvalid-aucpr:0.24910\n",
            "[606]\ttrain-aucpr:0.23554\tvalid-aucpr:0.24836\n",
            "[0]\ttrain-aucpr:0.12024\tvalid-aucpr:0.12171\n",
            "[100]\ttrain-aucpr:0.19165\tvalid-aucpr:0.25439\n",
            "[200]\ttrain-aucpr:0.21460\tvalid-aucpr:0.24910\n",
            "[300]\ttrain-aucpr:0.23666\tvalid-aucpr:0.24647\n",
            "[317]\ttrain-aucpr:0.24120\tvalid-aucpr:0.24390\n",
            "[0]\ttrain-aucpr:0.12413\tvalid-aucpr:0.13568\n",
            "[100]\ttrain-aucpr:0.19164\tvalid-aucpr:0.25206\n",
            "[200]\ttrain-aucpr:0.21672\tvalid-aucpr:0.25332\n",
            "[300]\ttrain-aucpr:0.24297\tvalid-aucpr:0.23892\n",
            "[333]\ttrain-aucpr:0.25032\tvalid-aucpr:0.23767\n",
            "[0]\ttrain-aucpr:0.13132\tvalid-aucpr:0.13274\n",
            "[100]\ttrain-aucpr:0.19539\tvalid-aucpr:0.25411\n",
            "[200]\ttrain-aucpr:0.22397\tvalid-aucpr:0.23994\n",
            "[295]\ttrain-aucpr:0.24527\tvalid-aucpr:0.23954\n",
            "[0]\ttrain-aucpr:0.13823\tvalid-aucpr:0.15328\n",
            "[100]\ttrain-aucpr:0.19353\tvalid-aucpr:0.24333\n",
            "[200]\ttrain-aucpr:0.22528\tvalid-aucpr:0.23454\n",
            "[300]\ttrain-aucpr:0.25198\tvalid-aucpr:0.22759\n",
            "[311]\ttrain-aucpr:0.25516\tvalid-aucpr:0.22586\n",
            "[0]\ttrain-aucpr:0.14998\tvalid-aucpr:0.14012\n",
            "[100]\ttrain-aucpr:0.28759\tvalid-aucpr:0.22056\n",
            "[200]\ttrain-aucpr:0.33443\tvalid-aucpr:0.21390\n",
            "[255]\ttrain-aucpr:0.36377\tvalid-aucpr:0.21785\n",
            "[0]\ttrain-aucpr:0.15693\tvalid-aucpr:0.14671\n",
            "[100]\ttrain-aucpr:0.29777\tvalid-aucpr:0.23598\n",
            "[200]\ttrain-aucpr:0.35051\tvalid-aucpr:0.22834\n",
            "[225]\ttrain-aucpr:0.36358\tvalid-aucpr:0.22525\n",
            "[0]\ttrain-aucpr:0.16012\tvalid-aucpr:0.16082\n",
            "[100]\ttrain-aucpr:0.27910\tvalid-aucpr:0.22761\n",
            "[200]\ttrain-aucpr:0.33375\tvalid-aucpr:0.22433\n",
            "[228]\ttrain-aucpr:0.34803\tvalid-aucpr:0.22312\n",
            "[0]\ttrain-aucpr:0.17159\tvalid-aucpr:0.14850\n",
            "[100]\ttrain-aucpr:0.28141\tvalid-aucpr:0.22575\n",
            "[200]\ttrain-aucpr:0.34047\tvalid-aucpr:0.23242\n",
            "[300]\ttrain-aucpr:0.40717\tvalid-aucpr:0.22951\n",
            "[400]\ttrain-aucpr:0.46872\tvalid-aucpr:0.22599\n",
            "[440]\ttrain-aucpr:0.49346\tvalid-aucpr:0.22387\n",
            "[0]\ttrain-aucpr:0.14998\tvalid-aucpr:0.14012\n",
            "[100]\ttrain-aucpr:0.34227\tvalid-aucpr:0.21726\n",
            "[200]\ttrain-aucpr:0.47639\tvalid-aucpr:0.20364\n",
            "[213]\ttrain-aucpr:0.49230\tvalid-aucpr:0.20055\n",
            "[0]\ttrain-aucpr:0.15693\tvalid-aucpr:0.14671\n",
            "[100]\ttrain-aucpr:0.36850\tvalid-aucpr:0.21935\n",
            "[200]\ttrain-aucpr:0.49026\tvalid-aucpr:0.20411\n",
            "[241]\ttrain-aucpr:0.54913\tvalid-aucpr:0.19902\n",
            "[0]\ttrain-aucpr:0.16012\tvalid-aucpr:0.16082\n",
            "[100]\ttrain-aucpr:0.34155\tvalid-aucpr:0.22601\n",
            "[200]\ttrain-aucpr:0.48528\tvalid-aucpr:0.21536\n",
            "[245]\ttrain-aucpr:0.54712\tvalid-aucpr:0.21827\n",
            "[0]\ttrain-aucpr:0.17159\tvalid-aucpr:0.14850\n",
            "[100]\ttrain-aucpr:0.35785\tvalid-aucpr:0.22657\n",
            "[200]\ttrain-aucpr:0.50728\tvalid-aucpr:0.21685\n",
            "[231]\ttrain-aucpr:0.54671\tvalid-aucpr:0.21373\n",
            "[0]\ttrain-aucpr:0.15142\tvalid-aucpr:0.14871\n",
            "[100]\ttrain-aucpr:0.28289\tvalid-aucpr:0.23994\n",
            "[200]\ttrain-aucpr:0.32679\tvalid-aucpr:0.23488\n",
            "[262]\ttrain-aucpr:0.35477\tvalid-aucpr:0.23091\n",
            "[0]\ttrain-aucpr:0.16198\tvalid-aucpr:0.16429\n",
            "[100]\ttrain-aucpr:0.29140\tvalid-aucpr:0.24499\n",
            "[200]\ttrain-aucpr:0.34123\tvalid-aucpr:0.23697\n",
            "[233]\ttrain-aucpr:0.35821\tvalid-aucpr:0.23424\n",
            "[0]\ttrain-aucpr:0.16312\tvalid-aucpr:0.16783\n",
            "[100]\ttrain-aucpr:0.27848\tvalid-aucpr:0.23152\n",
            "[200]\ttrain-aucpr:0.33214\tvalid-aucpr:0.23039\n",
            "[300]\ttrain-aucpr:0.38177\tvalid-aucpr:0.23428\n",
            "[400]\ttrain-aucpr:0.43639\tvalid-aucpr:0.22948\n",
            "[500]\ttrain-aucpr:0.48693\tvalid-aucpr:0.22692\n",
            "[501]\ttrain-aucpr:0.48743\tvalid-aucpr:0.22640\n",
            "[0]\ttrain-aucpr:0.17392\tvalid-aucpr:0.14642\n",
            "[100]\ttrain-aucpr:0.27927\tvalid-aucpr:0.23683\n",
            "[200]\ttrain-aucpr:0.32979\tvalid-aucpr:0.24032\n",
            "[300]\ttrain-aucpr:0.38568\tvalid-aucpr:0.23820\n",
            "[376]\ttrain-aucpr:0.42557\tvalid-aucpr:0.23458\n",
            "[0]\ttrain-aucpr:0.15142\tvalid-aucpr:0.14871\n",
            "[100]\ttrain-aucpr:0.33167\tvalid-aucpr:0.22311\n",
            "[200]\ttrain-aucpr:0.44359\tvalid-aucpr:0.21560\n",
            "[217]\ttrain-aucpr:0.46209\tvalid-aucpr:0.21144\n",
            "[0]\ttrain-aucpr:0.16198\tvalid-aucpr:0.16429\n",
            "[100]\ttrain-aucpr:0.35320\tvalid-aucpr:0.23239\n",
            "[200]\ttrain-aucpr:0.48025\tvalid-aucpr:0.21307\n",
            "[216]\ttrain-aucpr:0.49999\tvalid-aucpr:0.21058\n",
            "[0]\ttrain-aucpr:0.16312\tvalid-aucpr:0.16783\n",
            "[100]\ttrain-aucpr:0.32698\tvalid-aucpr:0.22975\n",
            "[200]\ttrain-aucpr:0.45808\tvalid-aucpr:0.21380\n",
            "[242]\ttrain-aucpr:0.51395\tvalid-aucpr:0.20643\n",
            "[0]\ttrain-aucpr:0.17392\tvalid-aucpr:0.14642\n",
            "[100]\ttrain-aucpr:0.35371\tvalid-aucpr:0.23458\n",
            "[200]\ttrain-aucpr:0.48855\tvalid-aucpr:0.22385\n",
            "[229]\ttrain-aucpr:0.52921\tvalid-aucpr:0.21963\n",
            "[0]\ttrain-aucpr:0.11934\tvalid-aucpr:0.12128\n",
            "[100]\ttrain-aucpr:0.17614\tvalid-aucpr:0.25407\n",
            "[200]\ttrain-aucpr:0.18855\tvalid-aucpr:0.25480\n",
            "[300]\ttrain-aucpr:0.20101\tvalid-aucpr:0.25762\n",
            "[400]\ttrain-aucpr:0.21168\tvalid-aucpr:0.25671\n",
            "[457]\ttrain-aucpr:0.21679\tvalid-aucpr:0.25494\n",
            "[0]\ttrain-aucpr:0.12409\tvalid-aucpr:0.13600\n",
            "[100]\ttrain-aucpr:0.17359\tvalid-aucpr:0.25014\n",
            "[200]\ttrain-aucpr:0.18707\tvalid-aucpr:0.25585\n",
            "[300]\ttrain-aucpr:0.20012\tvalid-aucpr:0.25569\n",
            "[400]\ttrain-aucpr:0.21042\tvalid-aucpr:0.25550\n",
            "[434]\ttrain-aucpr:0.21407\tvalid-aucpr:0.25423\n",
            "[0]\ttrain-aucpr:0.12435\tvalid-aucpr:0.10916\n",
            "[100]\ttrain-aucpr:0.16996\tvalid-aucpr:0.22969\n",
            "[200]\ttrain-aucpr:0.18838\tvalid-aucpr:0.25159\n",
            "[300]\ttrain-aucpr:0.20229\tvalid-aucpr:0.25276\n",
            "[400]\ttrain-aucpr:0.21595\tvalid-aucpr:0.25112\n",
            "[463]\ttrain-aucpr:0.22314\tvalid-aucpr:0.25012\n",
            "[0]\ttrain-aucpr:0.13121\tvalid-aucpr:0.13289\n",
            "[100]\ttrain-aucpr:0.16729\tvalid-aucpr:0.23206\n",
            "[200]\ttrain-aucpr:0.18554\tvalid-aucpr:0.25351\n",
            "[300]\ttrain-aucpr:0.19876\tvalid-aucpr:0.25254\n",
            "[400]\ttrain-aucpr:0.21002\tvalid-aucpr:0.25179\n",
            "[446]\ttrain-aucpr:0.21666\tvalid-aucpr:0.24831\n",
            "[0]\ttrain-aucpr:0.11934\tvalid-aucpr:0.12128\n",
            "[100]\ttrain-aucpr:0.19047\tvalid-aucpr:0.24976\n",
            "[200]\ttrain-aucpr:0.21309\tvalid-aucpr:0.24395\n",
            "[300]\ttrain-aucpr:0.23267\tvalid-aucpr:0.23761\n",
            "[332]\ttrain-aucpr:0.24162\tvalid-aucpr:0.23547\n",
            "[0]\ttrain-aucpr:0.12409\tvalid-aucpr:0.13600\n",
            "[100]\ttrain-aucpr:0.19085\tvalid-aucpr:0.25000\n",
            "[200]\ttrain-aucpr:0.21673\tvalid-aucpr:0.24299\n",
            "[287]\ttrain-aucpr:0.24195\tvalid-aucpr:0.22516\n",
            "[0]\ttrain-aucpr:0.12435\tvalid-aucpr:0.10916\n",
            "[100]\ttrain-aucpr:0.19201\tvalid-aucpr:0.24673\n",
            "[200]\ttrain-aucpr:0.21974\tvalid-aucpr:0.23728\n",
            "[288]\ttrain-aucpr:0.23942\tvalid-aucpr:0.23638\n",
            "[0]\ttrain-aucpr:0.13121\tvalid-aucpr:0.13289\n",
            "[100]\ttrain-aucpr:0.19435\tvalid-aucpr:0.24995\n",
            "[200]\ttrain-aucpr:0.22245\tvalid-aucpr:0.24179\n",
            "[291]\ttrain-aucpr:0.24848\tvalid-aucpr:0.23551\n",
            "[0]\ttrain-aucpr:0.12264\tvalid-aucpr:0.14234\n",
            "[100]\ttrain-aucpr:0.17434\tvalid-aucpr:0.25677\n",
            "[200]\ttrain-aucpr:0.18675\tvalid-aucpr:0.25783\n",
            "[300]\ttrain-aucpr:0.19817\tvalid-aucpr:0.25816\n",
            "[400]\ttrain-aucpr:0.20748\tvalid-aucpr:0.25621\n",
            "[459]\ttrain-aucpr:0.21206\tvalid-aucpr:0.25371\n",
            "[0]\ttrain-aucpr:0.12413\tvalid-aucpr:0.13568\n",
            "[100]\ttrain-aucpr:0.17355\tvalid-aucpr:0.25130\n",
            "[200]\ttrain-aucpr:0.18564\tvalid-aucpr:0.25563\n",
            "[300]\ttrain-aucpr:0.19708\tvalid-aucpr:0.25543\n",
            "[400]\ttrain-aucpr:0.20766\tvalid-aucpr:0.25515\n",
            "[444]\ttrain-aucpr:0.21199\tvalid-aucpr:0.25295\n",
            "[0]\ttrain-aucpr:0.12425\tvalid-aucpr:0.10945\n",
            "[100]\ttrain-aucpr:0.17036\tvalid-aucpr:0.23317\n",
            "[200]\ttrain-aucpr:0.18778\tvalid-aucpr:0.24895\n",
            "[300]\ttrain-aucpr:0.19984\tvalid-aucpr:0.25308\n",
            "[400]\ttrain-aucpr:0.21144\tvalid-aucpr:0.25309\n",
            "[500]\ttrain-aucpr:0.22053\tvalid-aucpr:0.25131\n",
            "[600]\ttrain-aucpr:0.23238\tvalid-aucpr:0.24986\n",
            "[625]\ttrain-aucpr:0.23499\tvalid-aucpr:0.24931\n",
            "[0]\ttrain-aucpr:0.13121\tvalid-aucpr:0.13289\n",
            "[100]\ttrain-aucpr:0.16722\tvalid-aucpr:0.23183\n",
            "[200]\ttrain-aucpr:0.18371\tvalid-aucpr:0.25047\n",
            "[300]\ttrain-aucpr:0.19710\tvalid-aucpr:0.24851\n",
            "[400]\ttrain-aucpr:0.20890\tvalid-aucpr:0.25366\n",
            "[500]\ttrain-aucpr:0.22051\tvalid-aucpr:0.25094\n",
            "[600]\ttrain-aucpr:0.23248\tvalid-aucpr:0.24327\n",
            "[635]\ttrain-aucpr:0.23607\tvalid-aucpr:0.24235\n",
            "[0]\ttrain-aucpr:0.12264\tvalid-aucpr:0.14234\n",
            "[100]\ttrain-aucpr:0.18871\tvalid-aucpr:0.25081\n",
            "[200]\ttrain-aucpr:0.21111\tvalid-aucpr:0.24557\n",
            "[300]\ttrain-aucpr:0.23005\tvalid-aucpr:0.24601\n",
            "[306]\ttrain-aucpr:0.23080\tvalid-aucpr:0.24419\n",
            "[0]\ttrain-aucpr:0.12413\tvalid-aucpr:0.13568\n",
            "[100]\ttrain-aucpr:0.19076\tvalid-aucpr:0.24897\n",
            "[200]\ttrain-aucpr:0.21518\tvalid-aucpr:0.24837\n",
            "[300]\ttrain-aucpr:0.24005\tvalid-aucpr:0.24001\n",
            "[339]\ttrain-aucpr:0.24910\tvalid-aucpr:0.23236\n",
            "[0]\ttrain-aucpr:0.12425\tvalid-aucpr:0.10945\n",
            "[100]\ttrain-aucpr:0.19165\tvalid-aucpr:0.24956\n",
            "[200]\ttrain-aucpr:0.21713\tvalid-aucpr:0.23327\n",
            "[300]\ttrain-aucpr:0.23908\tvalid-aucpr:0.23117\n",
            "[304]\ttrain-aucpr:0.23967\tvalid-aucpr:0.23074\n",
            "[0]\ttrain-aucpr:0.13121\tvalid-aucpr:0.13289\n",
            "[100]\ttrain-aucpr:0.19351\tvalid-aucpr:0.24584\n",
            "[200]\ttrain-aucpr:0.22053\tvalid-aucpr:0.23625\n",
            "[300]\ttrain-aucpr:0.24727\tvalid-aucpr:0.22947\n",
            "[329]\ttrain-aucpr:0.25360\tvalid-aucpr:0.22595\n",
            "[0]\ttrain-aucpr:0.14878\tvalid-aucpr:0.15765\n",
            "[100]\ttrain-aucpr:0.27562\tvalid-aucpr:0.21487\n",
            "[200]\ttrain-aucpr:0.32529\tvalid-aucpr:0.20848\n",
            "[256]\ttrain-aucpr:0.35386\tvalid-aucpr:0.20879\n",
            "[0]\ttrain-aucpr:0.14901\tvalid-aucpr:0.14321\n",
            "[100]\ttrain-aucpr:0.28702\tvalid-aucpr:0.21971\n",
            "[200]\ttrain-aucpr:0.34332\tvalid-aucpr:0.21835\n",
            "[291]\ttrain-aucpr:0.39394\tvalid-aucpr:0.21409\n",
            "[0]\ttrain-aucpr:0.15293\tvalid-aucpr:0.17615\n",
            "[100]\ttrain-aucpr:0.26808\tvalid-aucpr:0.21725\n",
            "[200]\ttrain-aucpr:0.32475\tvalid-aucpr:0.21423\n",
            "[207]\ttrain-aucpr:0.32745\tvalid-aucpr:0.21593\n",
            "[0]\ttrain-aucpr:0.16232\tvalid-aucpr:0.17291\n",
            "[100]\ttrain-aucpr:0.27047\tvalid-aucpr:0.21332\n",
            "[200]\ttrain-aucpr:0.32663\tvalid-aucpr:0.21936\n",
            "[203]\ttrain-aucpr:0.32891\tvalid-aucpr:0.21954\n",
            "[0]\ttrain-aucpr:0.14878\tvalid-aucpr:0.15765\n",
            "[100]\ttrain-aucpr:0.31983\tvalid-aucpr:0.20900\n",
            "[200]\ttrain-aucpr:0.44524\tvalid-aucpr:0.19471\n",
            "[239]\ttrain-aucpr:0.48349\tvalid-aucpr:0.19464\n",
            "[0]\ttrain-aucpr:0.14901\tvalid-aucpr:0.14321\n",
            "[100]\ttrain-aucpr:0.36008\tvalid-aucpr:0.21604\n",
            "[200]\ttrain-aucpr:0.49991\tvalid-aucpr:0.19261\n",
            "[247]\ttrain-aucpr:0.56225\tvalid-aucpr:0.18789\n",
            "[0]\ttrain-aucpr:0.15293\tvalid-aucpr:0.17615\n",
            "[100]\ttrain-aucpr:0.33113\tvalid-aucpr:0.20480\n",
            "[200]\ttrain-aucpr:0.45119\tvalid-aucpr:0.19659\n",
            "[207]\ttrain-aucpr:0.45866\tvalid-aucpr:0.19728\n",
            "[0]\ttrain-aucpr:0.16232\tvalid-aucpr:0.17291\n",
            "[100]\ttrain-aucpr:0.35153\tvalid-aucpr:0.21859\n",
            "[200]\ttrain-aucpr:0.49688\tvalid-aucpr:0.20318\n",
            "[230]\ttrain-aucpr:0.54208\tvalid-aucpr:0.20542\n",
            "[0]\ttrain-aucpr:0.14982\tvalid-aucpr:0.14277\n",
            "[100]\ttrain-aucpr:0.27171\tvalid-aucpr:0.23343\n",
            "[200]\ttrain-aucpr:0.31960\tvalid-aucpr:0.22743\n",
            "[254]\ttrain-aucpr:0.34353\tvalid-aucpr:0.22600\n",
            "[0]\ttrain-aucpr:0.15891\tvalid-aucpr:0.15460\n",
            "[100]\ttrain-aucpr:0.28385\tvalid-aucpr:0.23660\n",
            "[200]\ttrain-aucpr:0.33380\tvalid-aucpr:0.22678\n",
            "[230]\ttrain-aucpr:0.34832\tvalid-aucpr:0.22300\n",
            "[0]\ttrain-aucpr:0.15474\tvalid-aucpr:0.16015\n",
            "[100]\ttrain-aucpr:0.26993\tvalid-aucpr:0.23094\n",
            "[200]\ttrain-aucpr:0.31912\tvalid-aucpr:0.22873\n",
            "[230]\ttrain-aucpr:0.33333\tvalid-aucpr:0.22695\n",
            "[0]\ttrain-aucpr:0.16402\tvalid-aucpr:0.16648\n",
            "[100]\ttrain-aucpr:0.27263\tvalid-aucpr:0.22560\n",
            "[200]\ttrain-aucpr:0.32776\tvalid-aucpr:0.23163\n",
            "[208]\ttrain-aucpr:0.33076\tvalid-aucpr:0.23170\n",
            "[0]\ttrain-aucpr:0.14982\tvalid-aucpr:0.14277\n",
            "[100]\ttrain-aucpr:0.31599\tvalid-aucpr:0.20820\n",
            "[200]\ttrain-aucpr:0.42497\tvalid-aucpr:0.18677\n",
            "[214]\ttrain-aucpr:0.43889\tvalid-aucpr:0.18448\n",
            "[0]\ttrain-aucpr:0.15891\tvalid-aucpr:0.15460\n",
            "[100]\ttrain-aucpr:0.34955\tvalid-aucpr:0.22251\n",
            "[200]\ttrain-aucpr:0.46534\tvalid-aucpr:0.21840\n",
            "[233]\ttrain-aucpr:0.50637\tvalid-aucpr:0.21265\n",
            "[0]\ttrain-aucpr:0.15474\tvalid-aucpr:0.16015\n",
            "[100]\ttrain-aucpr:0.32884\tvalid-aucpr:0.22534\n",
            "[200]\ttrain-aucpr:0.44639\tvalid-aucpr:0.22058\n",
            "[232]\ttrain-aucpr:0.47408\tvalid-aucpr:0.22164\n",
            "[0]\ttrain-aucpr:0.16402\tvalid-aucpr:0.16648\n",
            "[100]\ttrain-aucpr:0.34018\tvalid-aucpr:0.22349\n",
            "[200]\ttrain-aucpr:0.47106\tvalid-aucpr:0.21218\n",
            "[211]\ttrain-aucpr:0.48561\tvalid-aucpr:0.21017\n",
            "    model                                             params  t_val    f1_val  \\\n",
            "270   XGB  {'spw_mult': 2.0, 'max_depth': 4, 'min_child_w...   0.81  0.314074   \n",
            "198   XGB  {'spw_mult': 0.5, 'max_depth': 4, 'min_child_w...   0.55  0.313830   \n",
            "230   XGB  {'spw_mult': 1.0, 'max_depth': 4, 'min_child_w...   0.70  0.313505   \n",
            "290   XGB  {'spw_mult': 4.0, 'max_depth': 4, 'min_child_w...   0.90  0.312997   \n",
            "226   XGB  {'spw_mult': 1.0, 'max_depth': 4, 'min_child_w...   0.69  0.312693   \n",
            "224   XGB  {'spw_mult': 1.0, 'max_depth': 4, 'min_child_w...   0.69  0.312347   \n",
            "258   XGB  {'spw_mult': 2.0, 'max_depth': 4, 'min_child_w...   0.81  0.312217   \n",
            "206   XGB  {'spw_mult': 0.5, 'max_depth': 4, 'min_child_w...   0.53  0.312157   \n",
            "296   XGB  {'spw_mult': 4.0, 'max_depth': 4, 'min_child_w...   0.89  0.311953   \n",
            "303   XGB  {'spw_mult': 4.0, 'max_depth': 4, 'min_child_w...   0.90  0.311436   \n",
            "\n",
            "     auprc_val  \n",
            "270   0.256478  \n",
            "198   0.260570  \n",
            "230   0.262526  \n",
            "290   0.257680  \n",
            "226   0.263321  \n",
            "224   0.265688  \n",
            "258   0.259110  \n",
            "206   0.259141  \n",
            "296   0.261825  \n",
            "303   0.249754  \n",
            "\n",
            "Best candidate: XGB {'spw_mult': 2.0, 'max_depth': 4, 'min_child_weight': 5, 'lr': 0.05, 'col': 0.9, 'sub': 0.7} t*= 0.81 F1_val= 0.3141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "proba_te = best_model.predict_proba(X_te)[:,1]\n",
        "print(\"Test ROC AUC:\", roc_auc_score(y_te, proba_te).round(4),\n",
        "      \"| AUPRC:\", average_precision_score(y_te, proba_te).round(4))\n",
        "print(\"Test @best_t:\", evaluate_at_threshold(y_te, proba_te, best_t))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2PTXWGWQaoh",
        "outputId": "d4f48d32-d5a5-4ae6-dc34-f4c164fc9ae9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ROC AUC: 0.8297 | AUPRC: 0.2294\n",
            "Test @best_t: {'threshold': 0.81, 'cm': [[10852, 1143], [131, 156]], 'accuracy': np.float64(0.8962709656407751), 'precision': np.float64(0.12009237875288684), 'recall': np.float64(0.5435540069686411), 'f1': np.float64(0.19672131147540983)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# เลือก LGBM และ XGB ที่ดีที่สุดจาก df_res อย่างละหนึ่ง\n",
        "best_lgb = next(r for r in results if r[\"model\"]==\"LGBM\" and r[\"f1_val\"]==df_res[df_res.model==\"LGBM\"][\"f1_val\"].max())\n",
        "best_xgb = next(r for r in results if r[\"model\"]==\"XGB\"  and r[\"f1_val\"]==df_res[df_res.model==\"XGB\"][\"f1_val\"].max())\n",
        "\n",
        "p_val_blend = 0.5*best_lgb[\"estimator\"].predict_proba(X_val)[:,1] + 0.5*best_xgb[\"estimator\"].predict_proba(X_val)[:,1]\n",
        "t_blend, f1_blend = find_best_threshold(y_val, p_val_blend, metric=\"f1\")\n",
        "print(\"Blend val: F1=\", round(f1_blend,4), \"t*=\", t_blend)\n",
        "\n",
        "p_te_blend = 0.5*best_lgb[\"estimator\"].predict_proba(X_te)[:,1] + 0.5*best_xgb[\"estimator\"].predict_proba(X_te)[:,1]\n",
        "print(\"Blend test:\", evaluate_at_threshold(y_te, p_te_blend, t_blend))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHU0uWG6QcFt",
        "outputId": "2c60c1e7-4275-4aee-dcf5-937c00ed1558"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blend val: F1= 0.2999 t*= 0.46\n",
            "Blend test: {'threshold': 0.46, 'cm': [[10717, 1278], [123, 164]], 'accuracy': np.float64(0.8859306301905228), 'precision': np.float64(0.11373092926490985), 'recall': np.float64(0.5714285714285714), 'f1': np.float64(0.189705031810295)}\n"
          ]
        }
      ]
    }
  ]
}