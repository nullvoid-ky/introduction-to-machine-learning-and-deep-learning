{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50247f38",
   "metadata": {},
   "source": [
    "# 03 — Flexible Model Controller (Parametrizable)\n",
    "*Updated: 2025-10-14 18:26*\n",
    "\n",
    "This version lets you pass **params** for `scaler`, `sampler`, and `clf` via either:\n",
    "1) Direct instances (`StandardScaler()`, `SMOTE(k_neighbors=7)`, `RandomForestClassifier(n_estimators=400)`) or\n",
    "2) **Keys + params** (e.g., `clf='rf', clf_params={'n_estimators':300, 'max_depth':10}`).\n",
    "\n",
    "It supports: LogisticRegression, DecisionTree, RandomForest, SVC, Perceptron (SLP), KNeighbors, and KMeans (with optional label mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99acbe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict, Any, Union\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "try:\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN\n",
    "    from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "    from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "except Exception:\n",
    "    ImbPipeline = None\n",
    "    SMOTE = RandomOverSampler = ADASYN = None\n",
    "    RandomUnderSampler = NearMiss = None\n",
    "    SMOTEENN = SMOTETomek = None\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def _ensure_2d(X):\n",
    "    if isinstance(X, pd.Series):\n",
    "        return X.to_frame()\n",
    "    return X\n",
    "\n",
    "def _extract_numeric_features(X):\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        return X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    return list(range(X.shape[1]))\n",
    "\n",
    "def _proba_from_estimator(clf, X):\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        proba = clf.predict_proba(X)\n",
    "        return proba[:, 1] if proba.ndim == 2 and proba.shape[1] >= 2 else proba.ravel()\n",
    "    if hasattr(clf, 'decision_function'):\n",
    "        score = clf.decision_function(X)\n",
    "        score = np.asarray(score).reshape(-1)\n",
    "        mn, mx = score.min(), score.max()\n",
    "        if mx - mn < 1e-12:\n",
    "            return np.full_like(score, 0.5, dtype=float)\n",
    "        return (score - mn) / (mx - mn)\n",
    "    return clf.predict(X)\n",
    "\n",
    "# ---------------- Registries ----------------\n",
    "SCALERS = {\n",
    "    'standard': StandardScaler,\n",
    "    'minmax': MinMaxScaler,\n",
    "    'robust': RobustScaler,\n",
    "}\n",
    "\n",
    "SAMPLERS = {\n",
    "    'smote': SMOTE,\n",
    "    'ros': RandomOverSampler,\n",
    "    'adasyn': ADASYN,\n",
    "    'rus': RandomUnderSampler,\n",
    "    'nearmiss': NearMiss,\n",
    "    'smoteenn': SMOTEENN,\n",
    "    'smotetomek': SMOTETomek,\n",
    "}\n",
    "\n",
    "CLFS = {\n",
    "    'lr': LogisticRegression,\n",
    "    'logreg': LogisticRegression,\n",
    "    'decisiontree': DecisionTreeClassifier,\n",
    "    'dt': DecisionTreeClassifier,\n",
    "    'rf': RandomForestClassifier,\n",
    "    'randomforest': RandomForestClassifier,\n",
    "    'svm': SVC,\n",
    "    'svc': SVC,\n",
    "    'slp': Perceptron,\n",
    "    'perceptron': Perceptron,\n",
    "    'knn': KNeighborsClassifier,\n",
    "    'kmeans': KMeans,\n",
    "}\n",
    "\n",
    "def _build_component(component: Union[str, Any], params: Optional[Dict[str, Any]], registry: Dict[str, Any]):\n",
    "    if component is None:\n",
    "        return None\n",
    "    if not isinstance(component, str):\n",
    "        # already an instance\n",
    "        if params:\n",
    "            # try set_params if available\n",
    "            if hasattr(component, 'set_params'):\n",
    "                component.set_params(**params)\n",
    "        return component\n",
    "    key = component.lower()\n",
    "    if key not in registry or registry[key] is None:\n",
    "        raise ValueError(f\"Unknown or unavailable component key: {component}\")\n",
    "    cls = registry[key]\n",
    "    params = params or {}\n",
    "    # inject RANDOM_STATE if supported and not provided\n",
    "    if 'random_state' in cls().__dict__ if hasattr(cls, '__call__') else []:\n",
    "        params.setdefault('random_state', RANDOM_STATE)\n",
    "    try:\n",
    "        return cls(**params)\n",
    "    except TypeError:\n",
    "        return cls() if params is None else cls(**params)\n",
    "\n",
    "class FlexibleModel:\n",
    "    def __init__(self,\n",
    "                 scaler: Union[str, Any, None] = 'standard',\n",
    "                 sampler: Union[str, Any, None] = None,\n",
    "                 clf: Union[str, Any, None] = 'lr',\n",
    "                 scaler_params: Optional[Dict[str, Any]] = None,\n",
    "                 sampler_params: Optional[Dict[str, Any]] = None,\n",
    "                 clf_params: Optional[Dict[str, Any]] = None,\n",
    "                 numeric_only: bool = True):\n",
    "        self.numeric_only = numeric_only\n",
    "        self.scaler = _build_component(scaler, scaler_params, SCALERS) if scaler is not None else None\n",
    "        self.sampler = _build_component(sampler, sampler_params, SAMPLERS) if sampler is not None else None\n",
    "        self.clf = _build_component(clf, clf_params, CLFS) if clf is not None else LogisticRegression(max_iter=1000)\n",
    "        self.is_clustering = isinstance(self.clf, KMeans)\n",
    "        if isinstance(self.clf, SVC) and not self.is_clustering:\n",
    "            # ensure probability if not set\n",
    "            if not hasattr(self.clf, 'probability') or not getattr(self.clf, 'probability'):\n",
    "                self.clf.set_params(probability=True)\n",
    "        self.pipeline = None\n",
    "        self.cluster_label_map_ = None\n",
    "\n",
    "    def _build_preprocessor(self, X):\n",
    "        if self.scaler is None:\n",
    "            return None\n",
    "        X = _ensure_2d(X)\n",
    "        cols = _extract_numeric_features(X) if (self.numeric_only and isinstance(X, pd.DataFrame)) else (X.columns if isinstance(X, pd.DataFrame) else list(range(X.shape[1])))\n",
    "        num_pipe = Pipeline([\n",
    "            ('impute', SimpleImputer(strategy='median')),\n",
    "            ('scale', self.scaler)\n",
    "        ])\n",
    "        return ColumnTransformer([('num', num_pipe, cols)], remainder='passthrough')\n",
    "\n",
    "    def _make_pipeline(self, X):\n",
    "        pre = self._build_preprocessor(X)\n",
    "        steps = []\n",
    "        if pre is not None:\n",
    "            steps.append(('pre', pre))\n",
    "        steps.append(('clf', self.clf))\n",
    "        if self.sampler is not None:\n",
    "            if ImbPipeline is None:\n",
    "                raise RuntimeError('imblearn is required for sampler pipelines but is not available.')\n",
    "            self.pipeline = ImbPipeline(steps=[('pre', pre)] if pre is not None else [] + [('sampler', self.sampler), ('clf', self.clf)])\n",
    "        else:\n",
    "            self.pipeline = Pipeline(steps)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = _ensure_2d(X)\n",
    "        self._make_pipeline(X)\n",
    "        if self.is_clustering:\n",
    "            self.pipeline.fit(X)\n",
    "            if y is not None:\n",
    "                clusters = self.pipeline.predict(X)\n",
    "                y = np.asarray(y)\n",
    "                self.cluster_label_map_ = {}\n",
    "                for c in np.unique(clusters):\n",
    "                    mask = clusters == c\n",
    "                    vals, counts = np.unique(y[mask], return_counts=True)\n",
    "                    self.cluster_label_map_[c] = vals[np.argmax(counts)]\n",
    "            return self\n",
    "        if y is None:\n",
    "            raise ValueError('y must be provided for classification models.')\n",
    "        self.pipeline.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        X = _ensure_2d(X)\n",
    "        if self.is_clustering:\n",
    "            clusters = self.pipeline.predict(X)\n",
    "            if self.cluster_label_map_ is not None:\n",
    "                return np.array([self.cluster_label_map_.get(c, 0) for c in clusters])\n",
    "            return clusters\n",
    "        return self.pipeline.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = _ensure_2d(X)\n",
    "        if self.is_clustering:\n",
    "            clusters = self.pipeline.predict(X)\n",
    "            if self.cluster_label_map_ is not None:\n",
    "                labels = np.array([self.cluster_label_map_.get(c, 0) for c in clusters])\n",
    "                return labels.astype(float)\n",
    "            if hasattr(self.pipeline.named_steps['clf'], 'transform'):\n",
    "                d = self.pipeline.named_steps['clf'].transform(X)\n",
    "                d = np.linalg.norm(d, axis=1)\n",
    "                return (d.max() - d) / (d.max() - d.min() + 1e-12)\n",
    "            return np.zeros(len(X), dtype=float)\n",
    "        clf = self.pipeline.named_steps['clf']\n",
    "        # send X through preprocessor only if present\n",
    "        Xproc = self.pipeline[:-1].transform(X) if 'pre' in self.pipeline.named_steps else X\n",
    "        return _proba_from_estimator(clf, Xproc)\n",
    "\n",
    "    def score(self, X, y, metric: str = 'accuracy'):\n",
    "        metric = metric.lower()\n",
    "        y_pred = self.predict(X)\n",
    "        if metric in ('accuracy', 'acc'):\n",
    "            return accuracy_score(y, y_pred)\n",
    "        if metric in ('f1', 'f1_score'):\n",
    "            return f1_score(y, y_pred)\n",
    "        if metric in ('precision', 'prec'):\n",
    "            return precision_score(y, y_pred)\n",
    "        if metric in ('recall', 'tpr', 'sensitivity'):\n",
    "            return recall_score(y, y_pred)\n",
    "        if metric in ('roc_auc', 'auc'):\n",
    "            y_score = self.predict_proba(X)\n",
    "            return roc_auc_score(y, y_score)\n",
    "        raise ValueError(f'Unknown metric: {metric}')\n",
    "\n",
    "    def set_params(self, **kwargs):\n",
    "        \"\"\"Update params of underlying clf/scaler/sampler if available.\"\"\"\n",
    "        updated = []\n",
    "        for part_name in ('clf', 'scaler', 'sampler'):\n",
    "            part = getattr(self, part_name, None)\n",
    "            part_kwargs = kwargs.get(part_name) or kwargs.get(part_name + '_params')\n",
    "            if part is not None and part_kwargs:\n",
    "                if hasattr(part, 'set_params'):\n",
    "                    part.set_params(**part_kwargs)\n",
    "                    updated.append(part_name)\n",
    "        return updated\n",
    "\n",
    "    def get_pipeline(self):\n",
    "        return self.pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f1db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick examples (requires your X_train, y_train)\n",
    "# 1) Instances\n",
    "model1 = FlexibleModel(\n",
    "    scaler='standard',\n",
    "    sampler='smote',\n",
    "    clf='rf',\n",
    "    sampler_params={'k_neighbors': 7, 'random_state': 42},\n",
    "    clf_params={'n_estimators': 300, 'max_depth': None, 'random_state': 42}\n",
    ")\n",
    "# model1.fit(X_train, y_train)\n",
    "# y_pred = model1.predict(X_test)\n",
    "\n",
    "# 2) SVM with kernel/params\n",
    "model2 = FlexibleModel(clf='svm', clf_params={'kernel':'rbf', 'C':1.0, 'gamma':'scale'})\n",
    "\n",
    "# 3) KMeans with label mapping\n",
    "model3 = FlexibleModel(clf='kmeans', clf_params={'n_clusters':2, 'random_state':42})\n",
    "print('Parametrizable FlexibleModel ready ✅')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
